{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preview:\n",
      "                          geometry  num_of_lines  avg_angle_of_intersection  \\\n",
      "0    POINT (30.1132479 81.9040127)             3                   1.569418   \n",
      "1  POINT (30.11393889 81.90421187)             3                   0.000869   \n",
      "2  POINT (30.13443475 81.92446576)             3                   0.000869   \n",
      "3  POINT (30.12866542 81.91527886)             3                   0.001507   \n",
      "4  POINT (30.10870486 81.90333917)             4                   2.092366   \n",
      "\n",
      "   num_of_involved_line_intersections  \\\n",
      "0                                  20   \n",
      "1                                  16   \n",
      "2                                  16   \n",
      "3                                  20   \n",
      "4                                   7   \n",
      "\n",
      "   vicinity_of_involved_line_intersections  min_distance_to_endpoint  \\\n",
      "0                                 0.006751                 30.167739   \n",
      "1                                 0.005855                 30.168430   \n",
      "2                                 0.025495                 30.188933   \n",
      "3                                 0.031805                 30.183159   \n",
      "4                                 0.011274                 30.163172   \n",
      "\n",
      "   max_distance_to_endpoint  intersection_bounding_box_height  \\\n",
      "0                 30.216515                          2.280721   \n",
      "1                 30.177051                          0.740906   \n",
      "2                 30.198007                          0.740906   \n",
      "3                 30.202581                          1.954675   \n",
      "4                 30.163260                          0.028933   \n",
      "\n",
      "   intersection_bounding_box_width  error  intersecting_angles_variance  \\\n",
      "0                         0.002429      0                      1.137288   \n",
      "1                         0.000944      0                      1.106692   \n",
      "2                         0.000944      0                      1.106692   \n",
      "3                         0.002499      0                      1.111603   \n",
      "4                         0.000088      0                      0.196697   \n",
      "\n",
      "   vicinity_to_intersections  is_loop  shortest_perimeter  \n",
      "0                   0.013492     True            0.010618  \n",
      "1                   0.013665     True            0.010618  \n",
      "2                   0.034194     True            0.058085  \n",
      "3                   0.034205     True            0.038236  \n",
      "4                   0.027423     True            0.010618  \n",
      "\n",
      "Training set:\n",
      "Total data points: 8334\n",
      "error\n",
      "0    96.064315\n",
      "1     3.935685\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set:\n",
      "Total data points: 2084\n",
      "error\n",
      "0    95.681382\n",
      "1     4.318618\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:/Users/twool/Downloads/intersection_analysis_2D.csv\") \n",
    "\n",
    "# Print dataset head for debugging\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Convert is_point columns from TRUE/FALSE to 1/0\n",
    "df.replace({\"TRUE\": 1, \"FALSE\": 0, True: 1, False: 0}, inplace=True)\n",
    "\n",
    "# Undersample label 0, keep all label 1\n",
    "target_col = \"error\"\n",
    "label_0 = df[df[target_col] == 0]\n",
    "label_1 = df[df[target_col] == 1]\n",
    "\n",
    "# Randomly sample 10,000 from label 0\n",
    "label_0_sampled = label_0.sample(n=10000, random_state=42)\n",
    "df_balanced = pd.concat([label_0_sampled, label_1], ignore_index=True)\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Identify features and target\n",
    "ignore_cols = [\"geometry\"]\n",
    "features = df_balanced.drop(columns=ignore_cols + [target_col])\n",
    "target = df_balanced[target_col]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(\"\\nTraining set:\")\n",
    "print(f\"Total data points: {len(y_train)}\")\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(f\"Total data points: {len(y_test)}\")\n",
    "print(y_test.value_counts(normalize=True) * 100)\n",
    "\n",
    "# Standardize features for SVM\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Performance:\n",
      "\n",
      "Decision Tree - Train set:\n",
      "Accuracy: 1.0000\n",
      "F1-score: 1.0000\n",
      "False Positives: 0\n",
      "False Negatives: 0\n",
      "Percentage of Errors Correctly Identified: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00       328\n",
      "\n",
      "    accuracy                           1.00      8334\n",
      "   macro avg       1.00      1.00      1.00      8334\n",
      "weighted avg       1.00      1.00      1.00      8334\n",
      "\n",
      "\n",
      "Decision Tree - Test set:\n",
      "Accuracy: 0.9765\n",
      "F1-score: 0.7263\n",
      "False Positives: 24\n",
      "False Negatives: 25\n",
      "Percentage of Errors Correctly Identified: 72.22%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1994\n",
      "           1       0.73      0.72      0.73        90\n",
      "\n",
      "    accuracy                           0.98      2084\n",
      "   macro avg       0.86      0.86      0.86      2084\n",
      "weighted avg       0.98      0.98      0.98      2084\n",
      "\n",
      "Cross-validation accuracy scores: [0.97420516 0.9760048  0.97240552 0.98380324 0.96758703]\n",
      "Mean cross-validation accuracy: 0.9748\n",
      "\n",
      "Random Forest Performance:\n",
      "\n",
      "Random Forest - Train set:\n",
      "Accuracy: 1.0000\n",
      "F1-score: 1.0000\n",
      "False Positives: 0\n",
      "False Negatives: 0\n",
      "Percentage of Errors Correctly Identified: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00       328\n",
      "\n",
      "    accuracy                           1.00      8334\n",
      "   macro avg       1.00      1.00      1.00      8334\n",
      "weighted avg       1.00      1.00      1.00      8334\n",
      "\n",
      "\n",
      "Random Forest - Test set:\n",
      "Accuracy: 0.9866\n",
      "F1-score: 0.8250\n",
      "False Positives: 4\n",
      "False Negatives: 24\n",
      "Percentage of Errors Correctly Identified: 73.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1994\n",
      "           1       0.94      0.73      0.83        90\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.97      0.87      0.91      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "Cross-validation accuracy scores: [0.98260348 0.97960408 0.98260348 0.9880024  0.9819928 ]\n",
      "Mean cross-validation accuracy: 0.9830\n",
      "\n",
      "SVM (Linear Kernel) Performance:\n",
      "\n",
      "SVM (Linear Kernel) - Train set:\n",
      "Accuracy: 0.9657\n",
      "F1-score: 0.2667\n",
      "False Positives: 10\n",
      "False Negatives: 276\n",
      "Percentage of Errors Correctly Identified: 15.85%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      8006\n",
      "           1       0.84      0.16      0.27       328\n",
      "\n",
      "    accuracy                           0.97      8334\n",
      "   macro avg       0.90      0.58      0.62      8334\n",
      "weighted avg       0.96      0.97      0.95      8334\n",
      "\n",
      "\n",
      "SVM (Linear Kernel) - Test set:\n",
      "Accuracy: 0.9607\n",
      "F1-score: 0.2679\n",
      "False Positives: 7\n",
      "False Negatives: 75\n",
      "Percentage of Errors Correctly Identified: 16.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1994\n",
      "           1       0.68      0.17      0.27        90\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.82      0.58      0.62      2084\n",
      "weighted avg       0.95      0.96      0.95      2084\n",
      "\n",
      "Cross-validation accuracy scores: [0.96280744 0.96460708 0.96820636 0.96640672 0.96638655]\n",
      "Mean cross-validation accuracy: 0.9657\n",
      "\n",
      "SVM (RBF Kernel) Performance:\n",
      "\n",
      "SVM (RBF Kernel) - Train set:\n",
      "Accuracy: 0.9680\n",
      "F1-score: 0.3628\n",
      "False Positives: 15\n",
      "False Negatives: 252\n",
      "Percentage of Errors Correctly Identified: 23.17%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      8006\n",
      "           1       0.84      0.23      0.36       328\n",
      "\n",
      "    accuracy                           0.97      8334\n",
      "   macro avg       0.90      0.61      0.67      8334\n",
      "weighted avg       0.96      0.97      0.96      8334\n",
      "\n",
      "\n",
      "SVM (RBF Kernel) - Test set:\n",
      "Accuracy: 0.9616\n",
      "F1-score: 0.3443\n",
      "False Positives: 11\n",
      "False Negatives: 69\n",
      "Percentage of Errors Correctly Identified: 23.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1994\n",
      "           1       0.66      0.23      0.34        90\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.81      0.61      0.66      2084\n",
      "weighted avg       0.95      0.96      0.95      2084\n",
      "\n",
      "Cross-validation accuracy scores: [0.96460708 0.96460708 0.9670066  0.9670066  0.96518607]\n",
      "Mean cross-validation accuracy: 0.9657\n",
      "\n",
      "SVM (Polynomial Kernel) Performance:\n",
      "\n",
      "SVM (Polynomial Kernel) - Train set:\n",
      "Accuracy: 0.9681\n",
      "F1-score: 0.3575\n",
      "False Positives: 12\n",
      "False Negatives: 254\n",
      "Percentage of Errors Correctly Identified: 22.56%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      8006\n",
      "           1       0.86      0.23      0.36       328\n",
      "\n",
      "    accuracy                           0.97      8334\n",
      "   macro avg       0.91      0.61      0.67      8334\n",
      "weighted avg       0.96      0.97      0.96      8334\n",
      "\n",
      "\n",
      "SVM (Polynomial Kernel) - Test set:\n",
      "Accuracy: 0.9616\n",
      "F1-score: 0.2982\n",
      "False Positives: 7\n",
      "False Negatives: 73\n",
      "Percentage of Errors Correctly Identified: 18.89%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1994\n",
      "           1       0.71      0.19      0.30        90\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.84      0.59      0.64      2084\n",
      "weighted avg       0.95      0.96      0.95      2084\n",
      "\n",
      "Cross-validation accuracy scores: [0.96220756 0.96280744 0.9670066  0.96520696 0.96518607]\n",
      "Mean cross-validation accuracy: 0.9645\n",
      "\n",
      "SVM (Sigmoid Kernel) Performance:\n",
      "\n",
      "SVM (Sigmoid Kernel) - Train set:\n",
      "Accuracy: 0.9399\n",
      "F1-score: 0.1465\n",
      "False Positives: 216\n",
      "False Negatives: 285\n",
      "Percentage of Errors Correctly Identified: 13.11%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      8006\n",
      "           1       0.17      0.13      0.15       328\n",
      "\n",
      "    accuracy                           0.94      8334\n",
      "   macro avg       0.57      0.55      0.56      8334\n",
      "weighted avg       0.93      0.94      0.94      8334\n",
      "\n",
      "\n",
      "SVM (Sigmoid Kernel) - Test set:\n",
      "Accuracy: 0.9343\n",
      "F1-score: 0.0680\n",
      "False Positives: 52\n",
      "False Negatives: 85\n",
      "Percentage of Errors Correctly Identified: 5.56%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      1994\n",
      "           1       0.09      0.06      0.07        90\n",
      "\n",
      "    accuracy                           0.93      2084\n",
      "   macro avg       0.52      0.51      0.52      2084\n",
      "weighted avg       0.92      0.93      0.93      2084\n",
      "\n",
      "Cross-validation accuracy scores: [0.93821236 0.94121176 0.93341332 0.94481104 0.93817527]\n",
      "Mean cross-validation accuracy: 0.9392\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=20),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM (Linear Kernel)\": SVC(kernel='linear', random_state=42),\n",
    "    \"SVM (RBF Kernel)\": SVC(kernel='rbf', random_state=42),\n",
    "    \"SVM (Polynomial Kernel)\": SVC(kernel='poly', random_state=42),\n",
    "    \"SVM (Sigmoid Kernel)\": SVC(kernel='sigmoid', random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    \n",
    "    if \"SVM\" in name:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_train_pred = model.predict(X_train_scaled)\n",
    "        y_test_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    for dataset, y_true, y_pred in [(\"Train\", y_train, y_train_pred), (\"Test\", y_test, y_test_pred)]:\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        percent_errors_identified = (tp / (tp + fn)) * 100 if (tp + fn) > 0 else 0\n",
    "        \n",
    "        print(f\"\\n{name} - {dataset} set:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"F1-score: {f1:.4f}\")\n",
    "        print(f\"False Positives: {fp}\")\n",
    "        print(f\"False Negatives: {fn}\")\n",
    "        print(f\"Percentage of Errors Correctly Identified: {percent_errors_identified:.2f}%\")\n",
    "        print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    # Cross-validation\n",
    "    scores = cross_val_score(model, X_train_scaled if \"SVM\" in name else X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"Cross-validation accuracy scores: {scores}\")\n",
    "    print(f\"Mean cross-validation accuracy: {scores.mean():.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preview:\n",
      "                          geometry  num_of_lines  avg_angle_of_intersection  \\\n",
      "0    POINT (30.1132479 81.9040127)             3                   1.569418   \n",
      "1  POINT (30.11393889 81.90421187)             3                   0.000869   \n",
      "2  POINT (30.13443475 81.92446576)             3                   0.000869   \n",
      "3  POINT (30.12866542 81.91527886)             3                   0.001507   \n",
      "4  POINT (30.10870486 81.90333917)             4                   2.092366   \n",
      "\n",
      "   num_of_involved_line_intersections  \\\n",
      "0                                  20   \n",
      "1                                  16   \n",
      "2                                  16   \n",
      "3                                  20   \n",
      "4                                   7   \n",
      "\n",
      "   vicinity_of_involved_line_intersections  min_distance_to_endpoint  \\\n",
      "0                                 0.006751                 30.167739   \n",
      "1                                 0.005855                 30.168430   \n",
      "2                                 0.025495                 30.188933   \n",
      "3                                 0.031805                 30.183159   \n",
      "4                                 0.011274                 30.163172   \n",
      "\n",
      "   max_distance_to_endpoint  intersection_bounding_box_height  \\\n",
      "0                 30.216515                          2.280721   \n",
      "1                 30.177051                          0.740906   \n",
      "2                 30.198007                          0.740906   \n",
      "3                 30.202581                          1.954675   \n",
      "4                 30.163260                          0.028933   \n",
      "\n",
      "   intersection_bounding_box_width  error  intersecting_angles_variance  \\\n",
      "0                         0.002429      0                      1.137288   \n",
      "1                         0.000944      0                      1.106692   \n",
      "2                         0.000944      0                      1.106692   \n",
      "3                         0.002499      0                      1.111603   \n",
      "4                         0.000088      0                      0.196697   \n",
      "\n",
      "   vicinity_to_intersections  is_loop  shortest_perimeter  \n",
      "0                   0.013492     True            0.010618  \n",
      "1                   0.013665     True            0.010618  \n",
      "2                   0.034194     True            0.058085  \n",
      "3                   0.034205     True            0.038236  \n",
      "4                   0.027423     True            0.010618  \n",
      "\n",
      "Training set after SMOTE:\n",
      "Total data points: 16012\n",
      "error\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set (original):\n",
      "Total data points: 2084\n",
      "error\n",
      "0    95.681382\n",
      "1     4.318618\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Random Forest Performance:\n",
      "\n",
      "Random Forest - Train set:\n",
      "Accuracy: 1.0000\n",
      "F1-score: 1.0000\n",
      "False Positives: 0\n",
      "False Negatives: 0\n",
      "Percentage of Errors Correctly Identified: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00      8006\n",
      "\n",
      "    accuracy                           1.00     16012\n",
      "   macro avg       1.00      1.00      1.00     16012\n",
      "weighted avg       1.00      1.00      1.00     16012\n",
      "\n",
      "\n",
      "Random Forest - Test set:\n",
      "Accuracy: 0.9875\n",
      "F1-score: 0.8571\n",
      "False Positives: 14\n",
      "False Negatives: 12\n",
      "Percentage of Errors Correctly Identified: 86.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1994\n",
      "           1       0.85      0.87      0.86        90\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.92      0.93      0.93      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "\n",
      "Decision Tree Performance:\n",
      "\n",
      "Decision Tree - Train set:\n",
      "Accuracy: 1.0000\n",
      "F1-score: 1.0000\n",
      "False Positives: 0\n",
      "False Negatives: 0\n",
      "Percentage of Errors Correctly Identified: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00      8006\n",
      "\n",
      "    accuracy                           1.00     16012\n",
      "   macro avg       1.00      1.00      1.00     16012\n",
      "weighted avg       1.00      1.00      1.00     16012\n",
      "\n",
      "\n",
      "Decision Tree - Test set:\n",
      "Accuracy: 0.9707\n",
      "F1-score: 0.6995\n",
      "False Positives: 42\n",
      "False Negatives: 19\n",
      "Percentage of Errors Correctly Identified: 78.89%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1994\n",
      "           1       0.63      0.79      0.70        90\n",
      "\n",
      "    accuracy                           0.97      2084\n",
      "   macro avg       0.81      0.88      0.84      2084\n",
      "weighted avg       0.97      0.97      0.97      2084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE  # For augmenting the minority class\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:/Users/twool/Downloads/intersection_analysis_2D.csv\") \n",
    "\n",
    "# Print dataset head for debugging\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Convert is_point columns from TRUE/FALSE to 1/0\n",
    "df.replace({\"TRUE\": 1, \"FALSE\": 0, True: 1, False: 0}, inplace=True)\n",
    "\n",
    "# Undersample label 0, keep all label 1\n",
    "target_col = \"error\"\n",
    "label_0 = df[df[target_col] == 0]\n",
    "label_1 = df[df[target_col] == 1]\n",
    "\n",
    "# Randomly sample 10,000 from label 0\n",
    "label_0_sampled = label_0.sample(n=10000, random_state=42)\n",
    "df_balanced = pd.concat([label_0_sampled, label_1], ignore_index=True)\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Identify features and target\n",
    "ignore_cols = [\"geometry\"]\n",
    "features = df_balanced.drop(columns=ignore_cols + [target_col])\n",
    "target = df_balanced[target_col]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print dataset statistics after applying SMOTE\n",
    "print(\"\\nTraining set after SMOTE:\")\n",
    "print(f\"Total data points: {len(y_train_res)}\")\n",
    "print(y_train_res.value_counts(normalize=True) * 100)\n",
    "\n",
    "print(\"\\nTest set (original):\")\n",
    "print(f\"Total data points: {len(y_test)}\")\n",
    "print(y_test.value_counts(normalize=True) * 100)\n",
    "\n",
    "# Standardize features for SVM and Decision Tree\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train_res)\n",
    "y_train_rf_pred = rf_model.predict(X_train_scaled)\n",
    "y_test_rf_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"\\nRandom Forest Performance:\")\n",
    "for dataset, y_true, y_pred in [(\"Train\", y_train_res, y_train_rf_pred), (\"Test\", y_test, y_test_rf_pred)]:\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    percent_errors_identified = (tp / (tp + fn)) * 100 if (tp + fn) > 0 else 0\n",
    "\n",
    "    print(f\"\\nRandom Forest - {dataset} set:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"Percentage of Errors Correctly Identified: {percent_errors_identified:.2f}%\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Train Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_scaled, y_train_res)\n",
    "y_train_dt_pred = dt_model.predict(X_train_scaled)\n",
    "y_test_dt_pred = dt_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "print(\"\\nDecision Tree Performance:\")\n",
    "for dataset, y_true, y_pred in [(\"Train\", y_train_res, y_train_dt_pred), (\"Test\", y_test, y_test_dt_pred)]:\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    percent_errors_identified = (tp / (tp + fn)) * 100 if (tp + fn) > 0 else 0\n",
    "\n",
    "    print(f\"\\nDecision Tree - {dataset} set:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"Percentage of Errors Correctly Identified: {percent_errors_identified:.2f}%\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preview:\n",
      "                          geometry  num_of_lines  avg_angle_of_intersection  \\\n",
      "0    POINT (30.1132479 81.9040127)             3                   1.569418   \n",
      "1  POINT (30.11393889 81.90421187)             3                   0.000869   \n",
      "2  POINT (30.13443475 81.92446576)             3                   0.000869   \n",
      "3  POINT (30.12866542 81.91527886)             3                   0.001507   \n",
      "4  POINT (30.10870486 81.90333917)             4                   2.092366   \n",
      "\n",
      "   num_of_involved_line_intersections  \\\n",
      "0                                  20   \n",
      "1                                  16   \n",
      "2                                  16   \n",
      "3                                  20   \n",
      "4                                   7   \n",
      "\n",
      "   vicinity_of_involved_line_intersections  min_distance_to_endpoint  \\\n",
      "0                                 0.006751                 30.167739   \n",
      "1                                 0.005855                 30.168430   \n",
      "2                                 0.025495                 30.188933   \n",
      "3                                 0.031805                 30.183159   \n",
      "4                                 0.011274                 30.163172   \n",
      "\n",
      "   max_distance_to_endpoint  intersection_bounding_box_height  \\\n",
      "0                 30.216515                          2.280721   \n",
      "1                 30.177051                          0.740906   \n",
      "2                 30.198007                          0.740906   \n",
      "3                 30.202581                          1.954675   \n",
      "4                 30.163260                          0.028933   \n",
      "\n",
      "   intersection_bounding_box_width  error  intersecting_angles_variance  \\\n",
      "0                         0.002429      0                      1.137288   \n",
      "1                         0.000944      0                      1.106692   \n",
      "2                         0.000944      0                      1.106692   \n",
      "3                         0.002499      0                      1.111603   \n",
      "4                         0.000088      0                      0.196697   \n",
      "\n",
      "   vicinity_to_intersections  is_loop  shortest_perimeter  \n",
      "0                   0.013492     True            0.010618  \n",
      "1                   0.013665     True            0.010618  \n",
      "2                   0.034194     True            0.058085  \n",
      "3                   0.034205     True            0.038236  \n",
      "4                   0.027423     True            0.010618  \n",
      "\n",
      "Training set:\n",
      "Total data points: 8334\n",
      "error\n",
      "0    96.064315\n",
      "1     3.935685\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set:\n",
      "Total data points: 2084\n",
      "error\n",
      "0    95.681382\n",
      "1     4.318618\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:/Users/twool/Downloads/intersection_analysis_2D.csv\") \n",
    "\n",
    "# Print dataset head for debugging\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Convert is_point columns from TRUE/FALSE to 1/0\n",
    "df.replace({\"TRUE\": 1, \"FALSE\": 0, True: 1, False: 0}, inplace=True)\n",
    "\n",
    "# Undersample label 0, keep all label 1\n",
    "target_col = \"error\"\n",
    "label_0 = df[df[target_col] == 0]\n",
    "label_1 = df[df[target_col] == 1]\n",
    "\n",
    "# Randomly sample 10,000 from label 0\n",
    "label_0_sampled = label_0.sample(n=10000, random_state=42)\n",
    "df_balanced = pd.concat([label_0_sampled, label_1], ignore_index=True)\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Identify features and target\n",
    "ignore_cols = [\"geometry\"]\n",
    "features = df_balanced.drop(columns=ignore_cols + [target_col])\n",
    "target = df_balanced[target_col]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(\"\\nTraining set:\")\n",
    "print(f\"Total data points: {len(y_train)}\")\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(f\"Total data points: {len(y_test)}\")\n",
    "print(y_test.value_counts(normalize=True) * 100)\n",
    "\n",
    "# Standardize features for SVM\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN Performance:\n",
      "\n",
      "KNN - Train set:\n",
      "Accuracy: 0.9855\n",
      "F1-score: 0.8112\n",
      "False Positives: 53\n",
      "False Negatives: 68\n",
      "Percentage of Errors Correctly Identified: 79.27%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      8006\n",
      "           1       0.83      0.79      0.81       328\n",
      "\n",
      "    accuracy                           0.99      8334\n",
      "   macro avg       0.91      0.89      0.90      8334\n",
      "weighted avg       0.99      0.99      0.99      8334\n",
      "\n",
      "\n",
      "KNN - Test set:\n",
      "Accuracy: 0.9789\n",
      "F1-score: 0.7500\n",
      "False Positives: 20\n",
      "False Negatives: 24\n",
      "Percentage of Errors Correctly Identified: 73.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1994\n",
      "           1       0.77      0.73      0.75        90\n",
      "\n",
      "    accuracy                           0.98      2084\n",
      "   macro avg       0.88      0.86      0.87      2084\n",
      "weighted avg       0.98      0.98      0.98      2084\n",
      "\n",
      "\n",
      "KNN - Cross-validation Accuracy (5-fold): 0.9812 ± 0.0055\n",
      "\n",
      "SVM (Polynomial Kernel) Performance:\n",
      "\n",
      "SVM (Polynomial Kernel) - Train set:\n",
      "Accuracy: 0.9681\n",
      "F1-score: 0.3575\n",
      "False Positives: 12\n",
      "False Negatives: 254\n",
      "Percentage of Errors Correctly Identified: 22.56%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      8006\n",
      "           1       0.86      0.23      0.36       328\n",
      "\n",
      "    accuracy                           0.97      8334\n",
      "   macro avg       0.91      0.61      0.67      8334\n",
      "weighted avg       0.96      0.97      0.96      8334\n",
      "\n",
      "\n",
      "SVM (Polynomial Kernel) - Test set:\n",
      "Accuracy: 0.9616\n",
      "F1-score: 0.2982\n",
      "False Positives: 7\n",
      "False Negatives: 73\n",
      "Percentage of Errors Correctly Identified: 18.89%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1994\n",
      "           1       0.71      0.19      0.30        90\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.84      0.59      0.64      2084\n",
      "weighted avg       0.95      0.96      0.95      2084\n",
      "\n",
      "\n",
      "SVM (Polynomial Kernel) - Cross-validation Accuracy (5-fold): 0.9645 ± 0.0018\n",
      "\n",
      "Random Forest Performance:\n",
      "\n",
      "Random Forest - Train set:\n",
      "Accuracy: 1.0000\n",
      "F1-score: 1.0000\n",
      "False Positives: 0\n",
      "False Negatives: 0\n",
      "Percentage of Errors Correctly Identified: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00       328\n",
      "\n",
      "    accuracy                           1.00      8334\n",
      "   macro avg       1.00      1.00      1.00      8334\n",
      "weighted avg       1.00      1.00      1.00      8334\n",
      "\n",
      "\n",
      "Random Forest - Test set:\n",
      "Accuracy: 0.9866\n",
      "F1-score: 0.8250\n",
      "False Positives: 4\n",
      "False Negatives: 24\n",
      "Percentage of Errors Correctly Identified: 73.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1994\n",
      "           1       0.94      0.73      0.83        90\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.97      0.87      0.91      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "\n",
      "Random Forest - Cross-validation Accuracy (5-fold): 0.9830 ± 0.0028\n",
      "\n",
      "Gradient Boosting Performance:\n",
      "\n",
      "Gradient Boosting - Train set:\n",
      "Accuracy: 0.9874\n",
      "F1-score: 0.8247\n",
      "False Positives: 24\n",
      "False Negatives: 81\n",
      "Percentage of Errors Correctly Identified: 75.30%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      8006\n",
      "           1       0.91      0.75      0.82       328\n",
      "\n",
      "    accuracy                           0.99      8334\n",
      "   macro avg       0.95      0.88      0.91      8334\n",
      "weighted avg       0.99      0.99      0.99      8334\n",
      "\n",
      "\n",
      "Gradient Boosting - Test set:\n",
      "Accuracy: 0.9827\n",
      "F1-score: 0.7662\n",
      "False Positives: 5\n",
      "False Negatives: 31\n",
      "Percentage of Errors Correctly Identified: 65.56%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1994\n",
      "           1       0.92      0.66      0.77        90\n",
      "\n",
      "    accuracy                           0.98      2084\n",
      "   macro avg       0.95      0.83      0.88      2084\n",
      "weighted avg       0.98      0.98      0.98      2084\n",
      "\n",
      "\n",
      "Gradient Boosting - Cross-validation Accuracy (5-fold): 0.9800 ± 0.0033\n",
      "\n",
      "XGBoost Performance:\n",
      "\n",
      "XGBoost - Train set:\n",
      "Accuracy: 1.0000\n",
      "F1-score: 1.0000\n",
      "False Positives: 0\n",
      "False Negatives: 0\n",
      "Percentage of Errors Correctly Identified: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00       328\n",
      "\n",
      "    accuracy                           1.00      8334\n",
      "   macro avg       1.00      1.00      1.00      8334\n",
      "weighted avg       1.00      1.00      1.00      8334\n",
      "\n",
      "\n",
      "XGBoost - Test set:\n",
      "Accuracy: 0.9880\n",
      "F1-score: 0.8521\n",
      "False Positives: 7\n",
      "False Negatives: 18\n",
      "Percentage of Errors Correctly Identified: 80.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1994\n",
      "           1       0.91      0.80      0.85        90\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.95      0.90      0.92      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "\n",
      "XGBoost - Cross-validation Accuracy (5-fold): 0.9840 ± 0.0034\n",
      "\n",
      "LightGBM Performance:\n",
      "[LightGBM] [Info] Number of positive: 328, number of negative: 8006\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2352\n",
      "[LightGBM] [Info] Number of data points in the train set: 8334, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039357 -> initscore=-3.194933\n",
      "[LightGBM] [Info] Start training from score -3.194933\n",
      "\n",
      "LightGBM - Train set:\n",
      "Accuracy: 1.0000\n",
      "F1-score: 1.0000\n",
      "False Positives: 0\n",
      "False Negatives: 0\n",
      "Percentage of Errors Correctly Identified: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00       328\n",
      "\n",
      "    accuracy                           1.00      8334\n",
      "   macro avg       1.00      1.00      1.00      8334\n",
      "weighted avg       1.00      1.00      1.00      8334\n",
      "\n",
      "\n",
      "LightGBM - Test set:\n",
      "Accuracy: 0.9866\n",
      "F1-score: 0.8333\n",
      "False Positives: 8\n",
      "False Negatives: 20\n",
      "Percentage of Errors Correctly Identified: 77.78%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1994\n",
      "           1       0.90      0.78      0.83        90\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.94      0.89      0.91      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 263, number of negative: 6404\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2348\n",
      "[LightGBM] [Info] Number of data points in the train set: 6667, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039448 -> initscore=-3.192524\n",
      "[LightGBM] [Info] Start training from score -3.192524\n",
      "[LightGBM] [Info] Number of positive: 262, number of negative: 6405\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2345\n",
      "[LightGBM] [Info] Number of data points in the train set: 6667, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039298 -> initscore=-3.196490\n",
      "[LightGBM] [Info] Start training from score -3.196490\n",
      "[LightGBM] [Info] Number of positive: 262, number of negative: 6405\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2347\n",
      "[LightGBM] [Info] Number of data points in the train set: 6667, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039298 -> initscore=-3.196490\n",
      "[LightGBM] [Info] Start training from score -3.196490\n",
      "[LightGBM] [Info] Number of positive: 262, number of negative: 6405\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2344\n",
      "[LightGBM] [Info] Number of data points in the train set: 6667, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039298 -> initscore=-3.196490\n",
      "[LightGBM] [Info] Start training from score -3.196490\n",
      "[LightGBM] [Info] Number of positive: 263, number of negative: 6405\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2348\n",
      "[LightGBM] [Info] Number of data points in the train set: 6668, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039442 -> initscore=-3.192680\n",
      "[LightGBM] [Info] Start training from score -3.192680\n",
      "\n",
      "LightGBM - Cross-validation Accuracy (5-fold): 0.9839 ± 0.0024\n",
      "\n",
      "Gaussian Naive Bayes Performance:\n",
      "\n",
      "Gaussian Naive Bayes - Train set:\n",
      "Accuracy: 0.9314\n",
      "F1-score: 0.2759\n",
      "False Positives: 353\n",
      "False Negatives: 219\n",
      "Percentage of Errors Correctly Identified: 33.23%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      8006\n",
      "           1       0.24      0.33      0.28       328\n",
      "\n",
      "    accuracy                           0.93      8334\n",
      "   macro avg       0.60      0.64      0.62      8334\n",
      "weighted avg       0.94      0.93      0.94      8334\n",
      "\n",
      "\n",
      "Gaussian Naive Bayes - Test set:\n",
      "Accuracy: 0.9189\n",
      "F1-score: 0.2066\n",
      "False Positives: 101\n",
      "False Negatives: 68\n",
      "Percentage of Errors Correctly Identified: 24.44%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1994\n",
      "           1       0.18      0.24      0.21        90\n",
      "\n",
      "    accuracy                           0.92      2084\n",
      "   macro avg       0.57      0.60      0.58      2084\n",
      "weighted avg       0.93      0.92      0.92      2084\n",
      "\n",
      "\n",
      "Gaussian Naive Bayes - Cross-validation Accuracy (5-fold): 0.9314 ± 0.0047\n"
     ]
    }
   ],
   "source": [
    "# Core packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Boosting libraries\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"SVM (Polynomial Kernel)\": SVC(kernel='poly', degree=3),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100, random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    \n",
    "    # For models requiring scaling (SVM, XGBoost, GradientBoosting, LightGBM)\n",
    "    if name in [\"SVM (Polynomial Kernel)\", \"XGBoost\", \"Gradient Boosting\", \"LightGBM\"]:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_train_pred = model.predict(X_train_scaled)\n",
    "        y_test_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    for dataset, y_true, y_pred in [(\"Train\", y_train, y_train_pred), (\"Test\", y_test, y_test_pred)]:\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        percent_errors_identified = (tp / (tp + fn)) * 100 if (tp + fn) > 0 else 0\n",
    "        \n",
    "        print(f\"\\n{name} - {dataset} set:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"F1-score: {f1:.4f}\")\n",
    "        print(f\"False Positives: {fp}\")\n",
    "        print(f\"False Negatives: {fn}\")\n",
    "        print(f\"Percentage of Errors Correctly Identified: {percent_errors_identified:.2f}%\")\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_scaled if name in [\"SVM (Polynomial Kernel)\", \"XGBoost\", \"Gradient Boosting\", \"LightGBM\"] else X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"\\n{name} - Cross-validation Accuracy (5-fold): {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Performance:\n",
      "Cross-validation accuracy (mean): 0.9638\n",
      "\n",
      "Logistic Regression - Train set:\n",
      "Accuracy: 0.9634\n",
      "F1-score: 0.2615\n",
      "False Positives: 31\n",
      "False Negatives: 274\n",
      "Percentage of Errors Correctly Identified: 16.46%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      8006\n",
      "           1       0.64      0.16      0.26       328\n",
      "\n",
      "    accuracy                           0.96      8334\n",
      "   macro avg       0.80      0.58      0.62      8334\n",
      "weighted avg       0.95      0.96      0.95      8334\n",
      "\n",
      "\n",
      "Logistic Regression - Test set:\n",
      "Accuracy: 0.9602\n",
      "F1-score: 0.2906\n",
      "False Positives: 10\n",
      "False Negatives: 73\n",
      "Percentage of Errors Correctly Identified: 18.89%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1994\n",
      "           1       0.63      0.19      0.29        90\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.80      0.59      0.64      2084\n",
      "weighted avg       0.95      0.96      0.95      2084\n",
      "\n",
      "\n",
      "SVM (Linear) Performance:\n",
      "Cross-validation accuracy (mean): 0.9657\n",
      "\n",
      "SVM (Linear) - Train set:\n",
      "Accuracy: 0.9657\n",
      "F1-score: 0.2667\n",
      "False Positives: 10\n",
      "False Negatives: 276\n",
      "Percentage of Errors Correctly Identified: 15.85%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      8006\n",
      "           1       0.84      0.16      0.27       328\n",
      "\n",
      "    accuracy                           0.97      8334\n",
      "   macro avg       0.90      0.58      0.62      8334\n",
      "weighted avg       0.96      0.97      0.95      8334\n",
      "\n",
      "\n",
      "SVM (Linear) - Test set:\n",
      "Accuracy: 0.9607\n",
      "F1-score: 0.2679\n",
      "False Positives: 7\n",
      "False Negatives: 75\n",
      "Percentage of Errors Correctly Identified: 16.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1994\n",
      "           1       0.68      0.17      0.27        90\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.82      0.58      0.62      2084\n",
      "weighted avg       0.95      0.96      0.95      2084\n",
      "\n",
      "\n",
      "SVM (RBF) Performance:\n",
      "Cross-validation accuracy (mean): 0.9657\n",
      "\n",
      "SVM (RBF) - Train set:\n",
      "Accuracy: 0.9680\n",
      "F1-score: 0.3628\n",
      "False Positives: 15\n",
      "False Negatives: 252\n",
      "Percentage of Errors Correctly Identified: 23.17%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      8006\n",
      "           1       0.84      0.23      0.36       328\n",
      "\n",
      "    accuracy                           0.97      8334\n",
      "   macro avg       0.90      0.61      0.67      8334\n",
      "weighted avg       0.96      0.97      0.96      8334\n",
      "\n",
      "\n",
      "SVM (RBF) - Test set:\n",
      "Accuracy: 0.9616\n",
      "F1-score: 0.3443\n",
      "False Positives: 11\n",
      "False Negatives: 69\n",
      "Percentage of Errors Correctly Identified: 23.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1994\n",
      "           1       0.66      0.23      0.34        90\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.81      0.61      0.66      2084\n",
      "weighted avg       0.95      0.96      0.95      2084\n",
      "\n",
      "\n",
      "KNN Performance:\n",
      "Cross-validation accuracy (mean): 0.9705\n",
      "\n",
      "KNN - Train set:\n",
      "Accuracy: 0.9797\n",
      "F1-score: 0.7071\n",
      "False Positives: 45\n",
      "False Negatives: 124\n",
      "Percentage of Errors Correctly Identified: 62.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      8006\n",
      "           1       0.82      0.62      0.71       328\n",
      "\n",
      "    accuracy                           0.98      8334\n",
      "   macro avg       0.90      0.81      0.85      8334\n",
      "weighted avg       0.98      0.98      0.98      8334\n",
      "\n",
      "\n",
      "KNN - Test set:\n",
      "Accuracy: 0.9645\n",
      "F1-score: 0.5488\n",
      "False Positives: 29\n",
      "False Negatives: 45\n",
      "Percentage of Errors Correctly Identified: 50.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1994\n",
      "           1       0.61      0.50      0.55        90\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.79      0.74      0.77      2084\n",
      "weighted avg       0.96      0.96      0.96      2084\n",
      "\n",
      "\n",
      "Random Forest Performance:\n",
      "Cross-validation accuracy (mean): 0.9832\n",
      "\n",
      "Random Forest - Train set:\n",
      "Accuracy: 1.0000\n",
      "F1-score: 1.0000\n",
      "False Positives: 0\n",
      "False Negatives: 0\n",
      "Percentage of Errors Correctly Identified: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00       328\n",
      "\n",
      "    accuracy                           1.00      8334\n",
      "   macro avg       1.00      1.00      1.00      8334\n",
      "weighted avg       1.00      1.00      1.00      8334\n",
      "\n",
      "\n",
      "Random Forest - Test set:\n",
      "Accuracy: 0.9866\n",
      "F1-score: 0.8250\n",
      "False Positives: 4\n",
      "False Negatives: 24\n",
      "Percentage of Errors Correctly Identified: 73.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1994\n",
      "           1       0.94      0.73      0.83        90\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.97      0.87      0.91      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "\n",
      "Voting Classifier Performance:\n",
      "Cross-validation accuracy (mean): 0.9658\n",
      "\n",
      "Voting Classifier - Train set:\n",
      "Accuracy: 0.9665\n",
      "F1-score: 0.2901\n",
      "False Positives: 8\n",
      "False Negatives: 271\n",
      "Percentage of Errors Correctly Identified: 17.38%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      8006\n",
      "           1       0.88      0.17      0.29       328\n",
      "\n",
      "    accuracy                           0.97      8334\n",
      "   macro avg       0.92      0.59      0.64      8334\n",
      "weighted avg       0.96      0.97      0.96      8334\n",
      "\n",
      "\n",
      "Voting Classifier - Test set:\n",
      "Accuracy: 0.9616\n",
      "F1-score: 0.2982\n",
      "False Positives: 7\n",
      "False Negatives: 73\n",
      "Percentage of Errors Correctly Identified: 18.89%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1994\n",
      "           1       0.71      0.19      0.30        90\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.84      0.59      0.64      2084\n",
      "weighted avg       0.95      0.96      0.95      2084\n",
      "\n",
      "\n",
      "Stacking Classifier Performance:\n",
      "Cross-validation accuracy (mean): 0.9832\n",
      "\n",
      "Stacking Classifier - Train set:\n",
      "Accuracy: 1.0000\n",
      "F1-score: 1.0000\n",
      "False Positives: 0\n",
      "False Negatives: 0\n",
      "Percentage of Errors Correctly Identified: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00       328\n",
      "\n",
      "    accuracy                           1.00      8334\n",
      "   macro avg       1.00      1.00      1.00      8334\n",
      "weighted avg       1.00      1.00      1.00      8334\n",
      "\n",
      "\n",
      "Stacking Classifier - Test set:\n",
      "Accuracy: 0.9866\n",
      "F1-score: 0.8250\n",
      "False Positives: 4\n",
      "False Negatives: 24\n",
      "Percentage of Errors Correctly Identified: 73.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1994\n",
      "           1       0.94      0.73      0.83        90\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.97      0.87      0.91      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "\n",
      "AdaBoost with Logistic Regression Performance:\n",
      "Cross-validation accuracy (mean): 0.9593\n",
      "\n",
      "AdaBoost with Logistic Regression - Train set:\n",
      "Accuracy: 0.9592\n",
      "F1-score: 0.2202\n",
      "False Positives: 60\n",
      "False Negatives: 280\n",
      "Percentage of Errors Correctly Identified: 14.63%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      8006\n",
      "           1       0.44      0.15      0.22       328\n",
      "\n",
      "    accuracy                           0.96      8334\n",
      "   macro avg       0.71      0.57      0.60      8334\n",
      "weighted avg       0.95      0.96      0.95      8334\n",
      "\n",
      "\n",
      "AdaBoost with Logistic Regression - Test set:\n",
      "Accuracy: 0.9568\n",
      "F1-score: 0.2241\n",
      "False Positives: 13\n",
      "False Negatives: 77\n",
      "Percentage of Errors Correctly Identified: 14.44%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1994\n",
      "           1       0.50      0.14      0.22        90\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.73      0.57      0.60      2084\n",
      "weighted avg       0.94      0.96      0.95      2084\n",
      "\n",
      "\n",
      "Bagging with Logistic Regression Performance:\n",
      "Cross-validation accuracy (mean): 0.9636\n",
      "\n",
      "Bagging with Logistic Regression - Train set:\n",
      "Accuracy: 0.9636\n",
      "F1-score: 0.2519\n",
      "False Positives: 26\n",
      "False Negatives: 277\n",
      "Percentage of Errors Correctly Identified: 15.55%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      8006\n",
      "           1       0.66      0.16      0.25       328\n",
      "\n",
      "    accuracy                           0.96      8334\n",
      "   macro avg       0.81      0.58      0.62      8334\n",
      "weighted avg       0.95      0.96      0.95      8334\n",
      "\n",
      "\n",
      "Bagging with Logistic Regression - Test set:\n",
      "Accuracy: 0.9607\n",
      "F1-score: 0.2931\n",
      "False Positives: 9\n",
      "False Negatives: 73\n",
      "Percentage of Errors Correctly Identified: 18.89%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1994\n",
      "           1       0.65      0.19      0.29        90\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.81      0.59      0.64      2084\n",
      "weighted avg       0.95      0.96      0.95      2084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# Standardize features for SVM and Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define base models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"SVM (Linear)\": SVC(kernel='linear', random_state=42),\n",
    "    \"SVM (RBF)\": SVC(kernel='rbf', random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "# Ensemble Methods\n",
    "ensemble_models = {\n",
    "    \"Voting Classifier\": VotingClassifier(estimators=[('lr', models[\"Logistic Regression\"]),\n",
    "                                                      ('rf', models[\"Random Forest\"]),\n",
    "                                                      ('svm', models[\"SVM (Linear)\"])], voting='hard'),\n",
    "    \"Stacking Classifier\": StackingClassifier(estimators=[('lr', models[\"Logistic Regression\"]),\n",
    "                                                          ('rf', models[\"Random Forest\"]),\n",
    "                                                          ('svm', models[\"SVM (Linear)\"])],\n",
    "                                              final_estimator=LogisticRegression()),\n",
    "    \"AdaBoost with Logistic Regression\": AdaBoostClassifier(models[\"Logistic Regression\"], random_state=42),\n",
    "    \"Bagging with Logistic Regression\": BaggingClassifier(models[\"Logistic Regression\"], random_state=42),\n",
    "}\n",
    "\n",
    "# Function to compute metrics\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    percent_errors_identified = (tp / (tp + fn)) * 100 if (tp + fn) > 0 else 0\n",
    "    return accuracy, f1, fp, fn, percent_errors_identified\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in {**models, **ensemble_models}.items():\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "\n",
    "    # Cross-validation scores (using 5-fold CV)\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"Cross-validation accuracy (mean): {cv_scores.mean():.4f}\")\n",
    "    \n",
    "    if isinstance(model, LogisticRegression) or isinstance(model, KNeighborsClassifier) or isinstance(model, SVC):\n",
    "        # Base models\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_train_pred = model.predict(X_train_scaled)\n",
    "        y_test_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        # Ensemble methods\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_train_pred = model.predict(X_train_scaled)\n",
    "        y_test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # For train and test metrics\n",
    "    for dataset, y_true, y_pred in [(\"Train\", y_train, y_train_pred), (\"Test\", y_test, y_test_pred)]:\n",
    "        accuracy, f1, fp, fn, percent_errors_identified = compute_metrics(y_true, y_pred)\n",
    "        \n",
    "        print(f\"\\n{name} - {dataset} set:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"F1-score: {f1:.4f}\")\n",
    "        print(f\"False Positives: {fp}\")\n",
    "        print(f\"False Negatives: {fn}\")\n",
    "        print(f\"Percentage of Errors Correctly Identified: {percent_errors_identified:.2f}%\")\n",
    "        print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP Classifier Performance:\n",
      "\n",
      "MLP - Train set:\n",
      "Accuracy: 0.9939\n",
      "F1-score: 0.9202\n",
      "False Positives: 17\n",
      "False Negatives: 34\n",
      "Percentage of Errors Correctly Identified: 89.63%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       0.95      0.90      0.92       328\n",
      "\n",
      "    accuracy                           0.99      8334\n",
      "   macro avg       0.97      0.95      0.96      8334\n",
      "weighted avg       0.99      0.99      0.99      8334\n",
      "\n",
      "\n",
      "MLP - Test set:\n",
      "Accuracy: 0.9746\n",
      "F1-score: 0.6936\n",
      "False Positives: 23\n",
      "False Negatives: 30\n",
      "Percentage of Errors Correctly Identified: 66.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1994\n",
      "           1       0.72      0.67      0.69        90\n",
      "\n",
      "    accuracy                           0.97      2084\n",
      "   macro avg       0.85      0.83      0.84      2084\n",
      "weighted avg       0.97      0.97      0.97      2084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Define MLP model\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(200,100,50,100,200), max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on train and test data\n",
    "y_train_pred_mlp = mlp.predict(X_train_scaled)\n",
    "y_test_pred_mlp = mlp.predict(X_test_scaled)\n",
    "\n",
    "# Function to compute metrics\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    percent_errors_identified = (tp / (tp + fn)) * 100 if (tp + fn) > 0 else 0\n",
    "    return accuracy, f1, fp, fn, percent_errors_identified\n",
    "\n",
    "# Print MLP Performance\n",
    "print(\"\\nMLP Classifier Performance:\")\n",
    "\n",
    "for dataset, y_true, y_pred in [(\"Train\", y_train, y_train_pred_mlp), (\"Test\", y_test, y_test_pred_mlp)]:\n",
    "    accuracy, f1, fp, fn, percent_errors_identified = compute_metrics(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\nMLP - {dataset} set:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"False Positives: {fp}\")\n",
    "    print(f\"False Negatives: {fn}\")\n",
    "    print(f\"Percentage of Errors Correctly Identified: {percent_errors_identified:.2f}%\")\n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preview:\n",
      "                          geometry  num_of_lines  avg_angle_of_intersection  \\\n",
      "0    POINT (30.1132479 81.9040127)             3                   1.569418   \n",
      "1  POINT (30.11393889 81.90421187)             3                   0.000869   \n",
      "2  POINT (30.13443475 81.92446576)             3                   0.000869   \n",
      "3  POINT (30.12866542 81.91527886)             3                   0.001507   \n",
      "4  POINT (30.10870486 81.90333917)             4                   2.092366   \n",
      "\n",
      "   num_of_involved_line_intersections  \\\n",
      "0                                  20   \n",
      "1                                  16   \n",
      "2                                  16   \n",
      "3                                  20   \n",
      "4                                   7   \n",
      "\n",
      "   vicinity_of_involved_line_intersections  min_distance_to_endpoint  \\\n",
      "0                                 0.006751                 30.167739   \n",
      "1                                 0.005855                 30.168430   \n",
      "2                                 0.025495                 30.188933   \n",
      "3                                 0.031805                 30.183159   \n",
      "4                                 0.011274                 30.163172   \n",
      "\n",
      "   max_distance_to_endpoint  intersection_bounding_box_height  \\\n",
      "0                 30.216515                          2.280721   \n",
      "1                 30.177051                          0.740906   \n",
      "2                 30.198007                          0.740906   \n",
      "3                 30.202581                          1.954675   \n",
      "4                 30.163260                          0.028933   \n",
      "\n",
      "   intersection_bounding_box_width  error  intersecting_angles_variance  \\\n",
      "0                         0.002429      0                      1.137288   \n",
      "1                         0.000944      0                      1.106692   \n",
      "2                         0.000944      0                      1.106692   \n",
      "3                         0.002499      0                      1.111603   \n",
      "4                         0.000088      0                      0.196697   \n",
      "\n",
      "   vicinity_to_intersections  is_loop  shortest_perimeter  \n",
      "0                   0.013492     True            0.010618  \n",
      "1                   0.013665     True            0.010618  \n",
      "2                   0.034194     True            0.058085  \n",
      "3                   0.034205     True            0.038236  \n",
      "4                   0.027423     True            0.010618  \n",
      "\n",
      "Training set after SMOTE:\n",
      "Total data points: 16012\n",
      "error\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set (original):\n",
      "Total data points: 2084\n",
      "error\n",
      "0    95.681382\n",
      "1     4.318618\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Random Forest Performance:\n",
      "\n",
      "Random Forest - Train set:\n",
      "Accuracy: 1.0000\n",
      "F1-score: 1.0000\n",
      "False Positives: 0\n",
      "False Negatives: 0\n",
      "Percentage of Errors Correctly Identified: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00      8006\n",
      "\n",
      "    accuracy                           1.00     16012\n",
      "   macro avg       1.00      1.00      1.00     16012\n",
      "weighted avg       1.00      1.00      1.00     16012\n",
      "\n",
      "\n",
      "Random Forest - Test set:\n",
      "Accuracy: 0.9875\n",
      "F1-score: 0.8571\n",
      "False Positives: 14\n",
      "False Negatives: 12\n",
      "Percentage of Errors Correctly Identified: 86.67%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1994\n",
      "           1       0.85      0.87      0.86        90\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.92      0.93      0.93      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "\n",
      "Decision Tree Performance:\n",
      "\n",
      "Decision Tree - Train set:\n",
      "Accuracy: 1.0000\n",
      "F1-score: 1.0000\n",
      "False Positives: 0\n",
      "False Negatives: 0\n",
      "Percentage of Errors Correctly Identified: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00      8006\n",
      "\n",
      "    accuracy                           1.00     16012\n",
      "   macro avg       1.00      1.00      1.00     16012\n",
      "weighted avg       1.00      1.00      1.00     16012\n",
      "\n",
      "\n",
      "Decision Tree - Test set:\n",
      "Accuracy: 0.9707\n",
      "F1-score: 0.6995\n",
      "False Positives: 42\n",
      "False Negatives: 19\n",
      "Percentage of Errors Correctly Identified: 78.89%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1994\n",
      "           1       0.63      0.79      0.70        90\n",
      "\n",
      "    accuracy                           0.97      2084\n",
      "   macro avg       0.81      0.88      0.84      2084\n",
      "weighted avg       0.97      0.97      0.97      2084\n",
      "\n",
      "\n",
      "MLP (Neural Network) Performance:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\twool\\AppData\\Local\\ESRI\\conda\\envs\\arcgispro-py3-clone\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP (Neural Network) - Train set:\n",
      "Accuracy: 0.9824\n",
      "F1-score: 0.9825\n",
      "False Positives: 210\n",
      "False Negatives: 72\n",
      "Percentage of Errors Correctly Identified: 99.10%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      8006\n",
      "           1       0.97      0.99      0.98      8006\n",
      "\n",
      "    accuracy                           0.98     16012\n",
      "   macro avg       0.98      0.98      0.98     16012\n",
      "weighted avg       0.98      0.98      0.98     16012\n",
      "\n",
      "\n",
      "MLP (Neural Network) - Test set:\n",
      "Accuracy: 0.9525\n",
      "F1-score: 0.5992\n",
      "False Positives: 83\n",
      "False Negatives: 16\n",
      "Percentage of Errors Correctly Identified: 82.22%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      1994\n",
      "           1       0.47      0.82      0.60        90\n",
      "\n",
      "    accuracy                           0.95      2084\n",
      "   macro avg       0.73      0.89      0.79      2084\n",
      "weighted avg       0.97      0.95      0.96      2084\n",
      "\n",
      "\n",
      "KNN Performance:\n",
      "\n",
      "KNN - Train set:\n",
      "Accuracy: 0.9769\n",
      "F1-score: 0.9773\n",
      "False Positives: 329\n",
      "False Negatives: 41\n",
      "Percentage of Errors Correctly Identified: 99.49%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      8006\n",
      "           1       0.96      0.99      0.98      8006\n",
      "\n",
      "    accuracy                           0.98     16012\n",
      "   macro avg       0.98      0.98      0.98     16012\n",
      "weighted avg       0.98      0.98      0.98     16012\n",
      "\n",
      "\n",
      "KNN - Test set:\n",
      "Accuracy: 0.9280\n",
      "F1-score: 0.4828\n",
      "False Positives: 130\n",
      "False Negatives: 20\n",
      "Percentage of Errors Correctly Identified: 77.78%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      1994\n",
      "           1       0.35      0.78      0.48        90\n",
      "\n",
      "    accuracy                           0.93      2084\n",
      "   macro avg       0.67      0.86      0.72      2084\n",
      "weighted avg       0.96      0.93      0.94      2084\n",
      "\n",
      "\n",
      "LightGBM Performance:\n",
      "[LightGBM] [Info] Number of positive: 8006, number of negative: 8006\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2551\n",
      "[LightGBM] [Info] Number of data points in the train set: 16012, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "LightGBM - Train set:\n",
      "Accuracy: 0.9988\n",
      "F1-score: 0.9988\n",
      "False Positives: 16\n",
      "False Negatives: 4\n",
      "Percentage of Errors Correctly Identified: 99.95%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00      8006\n",
      "\n",
      "    accuracy                           1.00     16012\n",
      "   macro avg       1.00      1.00      1.00     16012\n",
      "weighted avg       1.00      1.00      1.00     16012\n",
      "\n",
      "\n",
      "LightGBM - Test set:\n",
      "Accuracy: 0.9832\n",
      "F1-score: 0.8205\n",
      "False Positives: 25\n",
      "False Negatives: 10\n",
      "Percentage of Errors Correctly Identified: 88.89%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1994\n",
      "           1       0.76      0.89      0.82        90\n",
      "\n",
      "    accuracy                           0.98      2084\n",
      "   macro avg       0.88      0.94      0.91      2084\n",
      "weighted avg       0.98      0.98      0.98      2084\n",
      "\n",
      "\n",
      "XGBoost Performance:\n",
      "\n",
      "XGBoost - Train set:\n",
      "Accuracy: 0.9998\n",
      "F1-score: 0.9998\n",
      "False Positives: 4\n",
      "False Negatives: 0\n",
      "Percentage of Errors Correctly Identified: 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00      8006\n",
      "\n",
      "    accuracy                           1.00     16012\n",
      "   macro avg       1.00      1.00      1.00     16012\n",
      "weighted avg       1.00      1.00      1.00     16012\n",
      "\n",
      "\n",
      "XGBoost - Test set:\n",
      "Accuracy: 0.9803\n",
      "F1-score: 0.7853\n",
      "False Positives: 26\n",
      "False Negatives: 15\n",
      "Percentage of Errors Correctly Identified: 83.33%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1994\n",
      "           1       0.74      0.83      0.79        90\n",
      "\n",
      "    accuracy                           0.98      2084\n",
      "   macro avg       0.87      0.91      0.89      2084\n",
      "weighted avg       0.98      0.98      0.98      2084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:/Users/twool/Downloads/intersection_analysis_2D.csv\") \n",
    "\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Convert TRUE/FALSE to 1/0\n",
    "df.replace({\"TRUE\": 1, \"FALSE\": 0, True: 1, False: 0}, inplace=True)\n",
    "\n",
    "# Undersample label 0, keep all label 1\n",
    "target_col = \"error\"\n",
    "label_0 = df[df[target_col] == 0]\n",
    "label_1 = df[df[target_col] == 1]\n",
    "label_0_sampled = label_0.sample(n=10000, random_state=42)\n",
    "df_balanced = pd.concat([label_0_sampled, label_1], ignore_index=True)\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split features and target\n",
    "ignore_cols = [\"geometry\"]\n",
    "features = df_balanced.drop(columns=ignore_cols + [target_col])\n",
    "target = df_balanced[target_col]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# SMOTE to balance training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\nTraining set after SMOTE:\")\n",
    "print(f\"Total data points: {len(y_train_res)}\")\n",
    "print(y_train_res.value_counts(normalize=True) * 100)\n",
    "\n",
    "print(\"\\nTest set (original):\")\n",
    "print(f\"Total data points: {len(y_test)}\")\n",
    "print(y_test.value_counts(normalize=True) * 100)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"MLP (Neural Network)\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    \n",
    "    # Use scaled features for all models here since SMOTE + scaling is applied globally\n",
    "    model.fit(X_train_scaled, y_train_res)\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    for dataset, y_true, y_pred in [(\"Train\", y_train_res, y_train_pred), (\"Test\", y_test, y_test_pred)]:\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        percent_errors_identified = (tp / (tp + fn)) * 100 if (tp + fn) > 0 else 0\n",
    "\n",
    "        print(f\"\\n{name} - {dataset} set:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"F1-score: {f1:.4f}\")\n",
    "        print(f\"False Positives: {fp}\")\n",
    "        print(f\"False Negatives: {fn}\")\n",
    "        print(f\"Percentage of Errors Correctly Identified: {percent_errors_identified:.2f}%\")\n",
    "        print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preview:\n",
      "                          geometry  num_of_lines  avg_angle_of_intersection  \\\n",
      "0    POINT (30.1132479 81.9040127)             3                   1.569418   \n",
      "1  POINT (30.11393889 81.90421187)             3                   0.000869   \n",
      "2  POINT (30.13443475 81.92446576)             3                   0.000869   \n",
      "3  POINT (30.12866542 81.91527886)             3                   0.001507   \n",
      "4  POINT (30.10870486 81.90333917)             4                   2.092366   \n",
      "\n",
      "   num_of_involved_line_intersections  \\\n",
      "0                                  20   \n",
      "1                                  16   \n",
      "2                                  16   \n",
      "3                                  20   \n",
      "4                                   7   \n",
      "\n",
      "   vicinity_of_involved_line_intersections  min_distance_to_endpoint  \\\n",
      "0                                 0.006751                 30.167739   \n",
      "1                                 0.005855                 30.168430   \n",
      "2                                 0.025495                 30.188933   \n",
      "3                                 0.031805                 30.183159   \n",
      "4                                 0.011274                 30.163172   \n",
      "\n",
      "   max_distance_to_endpoint  intersection_bounding_box_height  \\\n",
      "0                 30.216515                          2.280721   \n",
      "1                 30.177051                          0.740906   \n",
      "2                 30.198007                          0.740906   \n",
      "3                 30.202581                          1.954675   \n",
      "4                 30.163260                          0.028933   \n",
      "\n",
      "   intersection_bounding_box_width  error  intersecting_angles_variance  \\\n",
      "0                         0.002429      0                      1.137288   \n",
      "1                         0.000944      0                      1.106692   \n",
      "2                         0.000944      0                      1.106692   \n",
      "3                         0.002499      0                      1.111603   \n",
      "4                         0.000088      0                      0.196697   \n",
      "\n",
      "   vicinity_to_intersections  is_loop  shortest_perimeter  \n",
      "0                   0.013492     True            0.010618  \n",
      "1                   0.013665     True            0.010618  \n",
      "2                   0.034194     True            0.058085  \n",
      "3                   0.034205     True            0.038236  \n",
      "4                   0.027423     True            0.010618  \n",
      "\n",
      "Training set after SMOTE:\n",
      "Total data points: 16012\n",
      "error\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set (original):\n",
      "Total data points: 2084\n",
      "error\n",
      "0    95.681382\n",
      "1     4.318618\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Random Forest Performance:\n",
      "\n",
      "RandomForestClassifier Classification Report (Train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00      8006\n",
      "\n",
      "    accuracy                           1.00     16012\n",
      "   macro avg       1.00      1.00      1.00     16012\n",
      "weighted avg       1.00      1.00      1.00     16012\n",
      "\n",
      "\n",
      "RandomForestClassifier Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1994\n",
      "           1       0.85      0.86      0.85        90\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.92      0.92      0.92      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "\n",
      "RandomForestClassifier Confusion Matrix (Test):\n",
      "[[1980   14]\n",
      " [  13   77]]\n",
      "\n",
      "MLP Performance:\n",
      "\n",
      "MLPClassifier Classification Report (Train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      8006\n",
      "           1       0.94      0.95      0.94      8006\n",
      "\n",
      "    accuracy                           0.94     16012\n",
      "   macro avg       0.94      0.94      0.94     16012\n",
      "weighted avg       0.94      0.94      0.94     16012\n",
      "\n",
      "\n",
      "MLPClassifier Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1994\n",
      "           1       0.30      0.86      0.45        90\n",
      "\n",
      "    accuracy                           0.91      2084\n",
      "   macro avg       0.65      0.88      0.70      2084\n",
      "weighted avg       0.96      0.91      0.93      2084\n",
      "\n",
      "\n",
      "MLPClassifier Confusion Matrix (Test):\n",
      "[[1818  176]\n",
      " [  13   77]]\n",
      "\n",
      "LightGBM Performance:\n",
      "[LightGBM] [Info] Number of positive: 8006, number of negative: 8006\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2545\n",
      "[LightGBM] [Info] Number of data points in the train set: 16012, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "LGBMClassifier Classification Report (Train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00      8006\n",
      "\n",
      "    accuracy                           1.00     16012\n",
      "   macro avg       1.00      1.00      1.00     16012\n",
      "weighted avg       1.00      1.00      1.00     16012\n",
      "\n",
      "\n",
      "LGBMClassifier Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1994\n",
      "           1       0.79      0.86      0.82        90\n",
      "\n",
      "    accuracy                           0.98      2084\n",
      "   macro avg       0.89      0.92      0.91      2084\n",
      "weighted avg       0.98      0.98      0.98      2084\n",
      "\n",
      "\n",
      "LGBMClassifier Confusion Matrix (Test):\n",
      "[[1973   21]\n",
      " [  13   77]]\n",
      "\n",
      "XGBoost Performance:\n",
      "\n",
      "XGBClassifier Classification Report (Train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00      8006\n",
      "\n",
      "    accuracy                           1.00     16012\n",
      "   macro avg       1.00      1.00      1.00     16012\n",
      "weighted avg       1.00      1.00      1.00     16012\n",
      "\n",
      "\n",
      "XGBClassifier Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1994\n",
      "           1       0.78      0.87      0.82        90\n",
      "\n",
      "    accuracy                           0.98      2084\n",
      "   macro avg       0.89      0.93      0.91      2084\n",
      "weighted avg       0.98      0.98      0.98      2084\n",
      "\n",
      "\n",
      "XGBClassifier Confusion Matrix (Test):\n",
      "[[1972   22]\n",
      " [  12   78]]\n",
      "\n",
      "CatBoost Performance:\n",
      "\n",
      "CatBoostClassifier Classification Report (Train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8006\n",
      "           1       1.00      1.00      1.00      8006\n",
      "\n",
      "    accuracy                           1.00     16012\n",
      "   macro avg       1.00      1.00      1.00     16012\n",
      "weighted avg       1.00      1.00      1.00     16012\n",
      "\n",
      "\n",
      "CatBoostClassifier Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1994\n",
      "           1       0.78      0.86      0.81        90\n",
      "\n",
      "    accuracy                           0.98      2084\n",
      "   macro avg       0.89      0.92      0.90      2084\n",
      "weighted avg       0.98      0.98      0.98      2084\n",
      "\n",
      "\n",
      "CatBoostClassifier Confusion Matrix (Test):\n",
      "[[1972   22]\n",
      " [  13   77]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequential Performance:\n",
      "Epoch 1/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 3:18 - loss: 0.9319 - accuracy: 0.1719\n",
      " 59/251 [======>.......................] - ETA: 0s - loss: 0.5900 - accuracy: 0.6846  \n",
      "117/251 [============>.................] - ETA: 0s - loss: 0.5177 - accuracy: 0.7429\n",
      "177/251 [====================>.........] - ETA: 0s - loss: 0.4686 - accuracy: 0.7728\n",
      "237/251 [===========================>..] - ETA: 0s - loss: 0.4449 - accuracy: 0.7872\n",
      "251/251 [==============================] - 1s 2ms/step - loss: 0.4397 - accuracy: 0.7908 - val_loss: 0.3111 - val_accuracy: 0.8565\n",
      "Epoch 2/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 5s - loss: 0.2580 - accuracy: 0.9375\n",
      " 55/251 [=====>........................] - ETA: 0s - loss: 0.2981 - accuracy: 0.8801\n",
      "118/251 [=============>................] - ETA: 0s - loss: 0.3011 - accuracy: 0.8783\n",
      "175/251 [===================>..........] - ETA: 0s - loss: 0.2872 - accuracy: 0.8848\n",
      "234/251 [==========================>...] - ETA: 0s - loss: 0.2798 - accuracy: 0.8898\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.2762 - accuracy: 0.8912 - val_loss: 0.4008 - val_accuracy: 0.8268\n",
      "Epoch 3/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 4s - loss: 0.3969 - accuracy: 0.7656\n",
      " 55/251 [=====>........................] - ETA: 0s - loss: 0.2471 - accuracy: 0.9020\n",
      "112/251 [============>.................] - ETA: 0s - loss: 0.2415 - accuracy: 0.9036\n",
      "169/251 [===================>..........] - ETA: 0s - loss: 0.2437 - accuracy: 0.9041\n",
      "223/251 [=========================>....] - ETA: 0s - loss: 0.2373 - accuracy: 0.9074\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.9093 - val_loss: 0.2062 - val_accuracy: 0.9170\n",
      "Epoch 4/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 4s - loss: 0.2520 - accuracy: 0.8906\n",
      " 55/251 [=====>........................] - ETA: 0s - loss: 0.2029 - accuracy: 0.9270\n",
      "114/251 [============>.................] - ETA: 0s - loss: 0.2060 - accuracy: 0.9208\n",
      "171/251 [===================>..........] - ETA: 0s - loss: 0.2026 - accuracy: 0.9224\n",
      "229/251 [==========================>...] - ETA: 0s - loss: 0.2015 - accuracy: 0.9227\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.2025 - accuracy: 0.9221 - val_loss: 0.2691 - val_accuracy: 0.8824\n",
      "Epoch 5/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 4s - loss: 0.3038 - accuracy: 0.8750\n",
      " 53/251 [=====>........................] - ETA: 0s - loss: 0.2091 - accuracy: 0.9195\n",
      "112/251 [============>.................] - ETA: 0s - loss: 0.2049 - accuracy: 0.9228\n",
      "167/251 [==================>...........] - ETA: 0s - loss: 0.1986 - accuracy: 0.9241\n",
      "224/251 [=========================>....] - ETA: 0s - loss: 0.1904 - accuracy: 0.9289\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.9297 - val_loss: 0.2531 - val_accuracy: 0.8906\n",
      "Epoch 6/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 4s - loss: 0.2850 - accuracy: 0.8750\n",
      " 54/251 [=====>........................] - ETA: 0s - loss: 0.1865 - accuracy: 0.9251\n",
      "113/251 [============>.................] - ETA: 0s - loss: 0.1715 - accuracy: 0.9344\n",
      "167/251 [==================>...........] - ETA: 0s - loss: 0.1697 - accuracy: 0.9340\n",
      "224/251 [=========================>....] - ETA: 0s - loss: 0.1708 - accuracy: 0.9345\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.9340 - val_loss: 0.1798 - val_accuracy: 0.9266\n",
      "Epoch 7/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 4s - loss: 0.1498 - accuracy: 0.9688\n",
      " 53/251 [=====>........................] - ETA: 0s - loss: 0.1589 - accuracy: 0.9384\n",
      "108/251 [===========>..................] - ETA: 0s - loss: 0.1681 - accuracy: 0.9353\n",
      "165/251 [==================>...........] - ETA: 0s - loss: 0.1668 - accuracy: 0.9369\n",
      "223/251 [=========================>....] - ETA: 0s - loss: 0.1625 - accuracy: 0.9383\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.1608 - accuracy: 0.9388 - val_loss: 0.2533 - val_accuracy: 0.8988\n",
      "Epoch 8/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 4s - loss: 0.1319 - accuracy: 0.9375\n",
      " 49/251 [====>.........................] - ETA: 0s - loss: 0.1500 - accuracy: 0.9455\n",
      "108/251 [===========>..................] - ETA: 0s - loss: 0.1535 - accuracy: 0.9431\n",
      "165/251 [==================>...........] - ETA: 0s - loss: 0.1534 - accuracy: 0.9436\n",
      "225/251 [=========================>....] - ETA: 0s - loss: 0.1532 - accuracy: 0.9426\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.9421 - val_loss: 0.1984 - val_accuracy: 0.9151\n",
      "Epoch 9/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 4s - loss: 0.2458 - accuracy: 0.9375\n",
      " 50/251 [====>.........................] - ETA: 0s - loss: 0.1504 - accuracy: 0.9453\n",
      "109/251 [============>.................] - ETA: 0s - loss: 0.1527 - accuracy: 0.9419\n",
      "165/251 [==================>...........] - ETA: 0s - loss: 0.1464 - accuracy: 0.9455\n",
      "222/251 [=========================>....] - ETA: 0s - loss: 0.1511 - accuracy: 0.9434\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.1506 - accuracy: 0.9435 - val_loss: 0.3968 - val_accuracy: 0.8282\n",
      "Epoch 10/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 4s - loss: 0.4372 - accuracy: 0.7656\n",
      " 55/251 [=====>........................] - ETA: 0s - loss: 0.1522 - accuracy: 0.9432\n",
      "113/251 [============>.................] - ETA: 0s - loss: 0.1553 - accuracy: 0.9399\n",
      "168/251 [===================>..........] - ETA: 0s - loss: 0.1505 - accuracy: 0.9435\n",
      "223/251 [=========================>....] - ETA: 0s - loss: 0.1492 - accuracy: 0.9440\n",
      "251/251 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9438 - val_loss: 0.1653 - val_accuracy: 0.9290\n",
      "\n",
      "  1/501 [..............................] - ETA: 45s\n",
      " 89/501 [====>.........................] - ETA: 0s \n",
      "179/501 [=========>....................] - ETA: 0s\n",
      "272/501 [===============>..............] - ETA: 0s\n",
      "318/501 [==================>...........] - ETA: 0s\n",
      "405/501 [=======================>......] - ETA: 0s\n",
      "466/501 [==========================>...] - ETA: 0s\n",
      "501/501 [==============================] - 0s 662us/step\n",
      "\n",
      " 1/66 [..............................] - ETA: 1s\n",
      "66/66 [==============================] - 0s 676us/step\n",
      "\n",
      "Sequential Classification Report (Train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.99      0.71      8006\n",
      "           1       0.96      0.21      0.35      8006\n",
      "\n",
      "    accuracy                           0.60     16012\n",
      "   macro avg       0.76      0.60      0.53     16012\n",
      "weighted avg       0.76      0.60      0.53     16012\n",
      "\n",
      "\n",
      "Sequential Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1994\n",
      "           1       0.51      0.21      0.30        90\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.74      0.60      0.64      2084\n",
      "weighted avg       0.95      0.96      0.95      2084\n",
      "\n",
      "\n",
      "Sequential Confusion Matrix (Test):\n",
      "[[1976   18]\n",
      " [  71   19]]\n",
      "\n",
      "Sequential Performance:\n",
      "Epoch 1/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 3:45 - loss: 0.6544 - accuracy: 0.5781\n",
      " 28/251 [==>...........................] - ETA: 0s - loss: 0.6891 - accuracy: 0.5078  \n",
      " 56/251 [=====>........................] - ETA: 0s - loss: 0.6618 - accuracy: 0.5645\n",
      " 84/251 [=========>....................] - ETA: 0s - loss: 0.6376 - accuracy: 0.6142\n",
      "109/251 [============>.................] - ETA: 0s - loss: 0.6360 - accuracy: 0.6038\n",
      "137/251 [===============>..............] - ETA: 0s - loss: 0.6257 - accuracy: 0.6168\n",
      "165/251 [==================>...........] - ETA: 0s - loss: 0.6210 - accuracy: 0.6263\n",
      "193/251 [======================>.......] - ETA: 0s - loss: 0.6094 - accuracy: 0.6392\n",
      "218/251 [=========================>....] - ETA: 0s - loss: 0.6043 - accuracy: 0.6406\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.5969 - accuracy: 0.6559\n",
      "251/251 [==============================] - 2s 3ms/step - loss: 0.5956 - accuracy: 0.6590 - val_loss: 0.5327 - val_accuracy: 0.8498\n",
      "Epoch 2/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 4s - loss: 0.5288 - accuracy: 0.8438\n",
      " 30/251 [==>...........................] - ETA: 0s - loss: 0.5248 - accuracy: 0.7359\n",
      " 59/251 [======>.......................] - ETA: 0s - loss: 0.5192 - accuracy: 0.7500\n",
      " 88/251 [=========>....................] - ETA: 0s - loss: 0.5171 - accuracy: 0.7544\n",
      "117/251 [============>.................] - ETA: 0s - loss: 0.5045 - accuracy: 0.7706\n",
      "145/251 [================>.............] - ETA: 0s - loss: 0.4965 - accuracy: 0.7768\n",
      "173/251 [===================>..........] - ETA: 0s - loss: 0.4910 - accuracy: 0.7815\n",
      "201/251 [=======================>......] - ETA: 0s - loss: 0.4822 - accuracy: 0.7880\n",
      "228/251 [==========================>...] - ETA: 0s - loss: 0.4769 - accuracy: 0.7939\n",
      "251/251 [==============================] - 1s 2ms/step - loss: 0.4756 - accuracy: 0.7900 - val_loss: 0.2834 - val_accuracy: 0.9247\n",
      "Epoch 3/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 5s - loss: 0.6696 - accuracy: 0.6406\n",
      " 26/251 [==>...........................] - ETA: 0s - loss: 0.4426 - accuracy: 0.8209\n",
      " 54/251 [=====>........................] - ETA: 0s - loss: 0.4094 - accuracy: 0.8507\n",
      " 82/251 [========>.....................] - ETA: 0s - loss: 0.4029 - accuracy: 0.8510\n",
      "109/251 [============>.................] - ETA: 0s - loss: 0.3969 - accuracy: 0.8546\n",
      "138/251 [===============>..............] - ETA: 0s - loss: 0.3917 - accuracy: 0.8566\n",
      "166/251 [==================>...........] - ETA: 0s - loss: 0.3888 - accuracy: 0.8554\n",
      "194/251 [======================>.......] - ETA: 0s - loss: 0.3848 - accuracy: 0.8557\n",
      "222/251 [=========================>....] - ETA: 0s - loss: 0.3803 - accuracy: 0.8577\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.3815 - accuracy: 0.8554\n",
      "251/251 [==============================] - 1s 2ms/step - loss: 0.3815 - accuracy: 0.8554 - val_loss: 0.4581 - val_accuracy: 0.8162\n",
      "Epoch 4/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 5s - loss: 0.4765 - accuracy: 0.7969\n",
      " 27/251 [==>...........................] - ETA: 0s - loss: 0.3774 - accuracy: 0.8473\n",
      " 56/251 [=====>........................] - ETA: 0s - loss: 0.3494 - accuracy: 0.8647\n",
      " 84/251 [=========>....................] - ETA: 0s - loss: 0.3582 - accuracy: 0.8599\n",
      "111/251 [============>.................] - ETA: 0s - loss: 0.3565 - accuracy: 0.8599\n",
      "138/251 [===============>..............] - ETA: 0s - loss: 0.3492 - accuracy: 0.8650\n",
      "165/251 [==================>...........] - ETA: 0s - loss: 0.3462 - accuracy: 0.8657\n",
      "193/251 [======================>.......] - ETA: 0s - loss: 0.3421 - accuracy: 0.8677\n",
      "220/251 [=========================>....] - ETA: 0s - loss: 0.3398 - accuracy: 0.8685\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.3364 - accuracy: 0.8701\n",
      "251/251 [==============================] - 1s 2ms/step - loss: 0.3363 - accuracy: 0.8703 - val_loss: 0.3353 - val_accuracy: 0.8632\n",
      "Epoch 5/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 5s - loss: 0.3840 - accuracy: 0.8594\n",
      " 24/251 [=>............................] - ETA: 0s - loss: 0.3009 - accuracy: 0.8900\n",
      " 53/251 [=====>........................] - ETA: 0s - loss: 0.2979 - accuracy: 0.8912\n",
      " 81/251 [========>.....................] - ETA: 0s - loss: 0.3024 - accuracy: 0.8891\n",
      "110/251 [============>.................] - ETA: 0s - loss: 0.3064 - accuracy: 0.8839\n",
      "138/251 [===============>..............] - ETA: 0s - loss: 0.3089 - accuracy: 0.8818\n",
      "166/251 [==================>...........] - ETA: 0s - loss: 0.3172 - accuracy: 0.8776\n",
      "195/251 [======================>.......] - ETA: 0s - loss: 0.3116 - accuracy: 0.8806\n",
      "223/251 [=========================>....] - ETA: 0s - loss: 0.3098 - accuracy: 0.8819\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.3097 - accuracy: 0.8816\n",
      "251/251 [==============================] - 1s 2ms/step - loss: 0.3099 - accuracy: 0.8814 - val_loss: 0.4759 - val_accuracy: 0.8085\n",
      "Epoch 6/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 5s - loss: 0.3984 - accuracy: 0.8281\n",
      " 26/251 [==>...........................] - ETA: 0s - loss: 0.2802 - accuracy: 0.8978\n",
      " 53/251 [=====>........................] - ETA: 0s - loss: 0.2926 - accuracy: 0.8909\n",
      " 82/251 [========>.....................] - ETA: 0s - loss: 0.2915 - accuracy: 0.8914\n",
      "110/251 [============>.................] - ETA: 0s - loss: 0.3008 - accuracy: 0.8864\n",
      "137/251 [===============>..............] - ETA: 0s - loss: 0.3011 - accuracy: 0.8852\n",
      "152/251 [=================>............] - ETA: 0s - loss: 0.2962 - accuracy: 0.8892\n",
      "177/251 [====================>.........] - ETA: 0s - loss: 0.2942 - accuracy: 0.8896\n",
      "199/251 [======================>.......] - ETA: 0s - loss: 0.2936 - accuracy: 0.8900\n",
      "227/251 [==========================>...] - ETA: 0s - loss: 0.2932 - accuracy: 0.8901\n",
      "251/251 [==============================] - 1s 2ms/step - loss: 0.2904 - accuracy: 0.8916 - val_loss: 0.3188 - val_accuracy: 0.8680\n",
      "Epoch 7/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 4s - loss: 0.3182 - accuracy: 0.8906\n",
      " 28/251 [==>...........................] - ETA: 0s - loss: 0.2787 - accuracy: 0.8996\n",
      " 57/251 [=====>........................] - ETA: 0s - loss: 0.2813 - accuracy: 0.8978\n",
      " 85/251 [=========>....................] - ETA: 0s - loss: 0.2815 - accuracy: 0.8961\n",
      "113/251 [============>.................] - ETA: 0s - loss: 0.2847 - accuracy: 0.8930\n",
      "141/251 [===============>..............] - ETA: 0s - loss: 0.2792 - accuracy: 0.8944\n",
      "168/251 [===================>..........] - ETA: 0s - loss: 0.2773 - accuracy: 0.8962\n",
      "195/251 [======================>.......] - ETA: 0s - loss: 0.2754 - accuracy: 0.8970\n",
      "223/251 [=========================>....] - ETA: 0s - loss: 0.2725 - accuracy: 0.8984\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.2724 - accuracy: 0.8988\n",
      "251/251 [==============================] - 1s 2ms/step - loss: 0.2724 - accuracy: 0.8988 - val_loss: 0.3970 - val_accuracy: 0.8373\n",
      "Epoch 8/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 4s - loss: 0.1004 - accuracy: 0.9844\n",
      " 27/251 [==>...........................] - ETA: 0s - loss: 0.2752 - accuracy: 0.8993\n",
      " 55/251 [=====>........................] - ETA: 0s - loss: 0.2654 - accuracy: 0.9000\n",
      " 83/251 [========>.....................] - ETA: 0s - loss: 0.2661 - accuracy: 0.9004\n",
      "111/251 [============>.................] - ETA: 0s - loss: 0.2648 - accuracy: 0.9026\n",
      "138/251 [===============>..............] - ETA: 0s - loss: 0.2622 - accuracy: 0.9033\n",
      "164/251 [==================>...........] - ETA: 0s - loss: 0.2628 - accuracy: 0.9027\n",
      "193/251 [======================>.......] - ETA: 0s - loss: 0.2606 - accuracy: 0.9036\n",
      "222/251 [=========================>....] - ETA: 0s - loss: 0.2601 - accuracy: 0.9032\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.2624 - accuracy: 0.9021\n",
      "251/251 [==============================] - 1s 2ms/step - loss: 0.2622 - accuracy: 0.9021 - val_loss: 0.2378 - val_accuracy: 0.8964\n",
      "Epoch 9/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 5s - loss: 0.2033 - accuracy: 0.9531\n",
      " 26/251 [==>...........................] - ETA: 0s - loss: 0.2492 - accuracy: 0.9123\n",
      " 54/251 [=====>........................] - ETA: 0s - loss: 0.2553 - accuracy: 0.9060\n",
      " 81/251 [========>.....................] - ETA: 0s - loss: 0.2545 - accuracy: 0.9051\n",
      "109/251 [============>.................] - ETA: 0s - loss: 0.2508 - accuracy: 0.9061\n",
      "136/251 [===============>..............] - ETA: 0s - loss: 0.2485 - accuracy: 0.9084\n",
      "163/251 [==================>...........] - ETA: 0s - loss: 0.2486 - accuracy: 0.9091\n",
      "191/251 [=====================>........] - ETA: 0s - loss: 0.2491 - accuracy: 0.9080\n",
      "218/251 [=========================>....] - ETA: 0s - loss: 0.2501 - accuracy: 0.9087\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.2478 - accuracy: 0.9084\n",
      "251/251 [==============================] - 1s 2ms/step - loss: 0.2477 - accuracy: 0.9085 - val_loss: 0.2127 - val_accuracy: 0.9074\n",
      "Epoch 10/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 5s - loss: 0.1850 - accuracy: 0.9375\n",
      " 25/251 [=>............................] - ETA: 0s - loss: 0.2484 - accuracy: 0.9162\n",
      " 53/251 [=====>........................] - ETA: 0s - loss: 0.2533 - accuracy: 0.9136\n",
      " 82/251 [========>.....................] - ETA: 0s - loss: 0.2542 - accuracy: 0.9083\n",
      "107/251 [===========>..................] - ETA: 0s - loss: 0.2516 - accuracy: 0.9100\n",
      "135/251 [===============>..............] - ETA: 0s - loss: 0.2462 - accuracy: 0.9097\n",
      "163/251 [==================>...........] - ETA: 0s - loss: 0.2436 - accuracy: 0.9105\n",
      "190/251 [=====================>........] - ETA: 0s - loss: 0.2424 - accuracy: 0.9105\n",
      "218/251 [=========================>....] - ETA: 0s - loss: 0.2450 - accuracy: 0.9095\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.2423 - accuracy: 0.9100\n",
      "251/251 [==============================] - 1s 2ms/step - loss: 0.2426 - accuracy: 0.9099 - val_loss: 0.2781 - val_accuracy: 0.8810\n",
      "\n",
      "  1/501 [..............................] - ETA: 39s\n",
      " 71/501 [===>..........................] - ETA: 0s \n",
      "142/501 [=======>......................] - ETA: 0s\n",
      "218/501 [============>.................] - ETA: 0s\n",
      "291/501 [================>.............] - ETA: 0s\n",
      "360/501 [====================>.........] - ETA: 0s\n",
      "428/501 [========================>.....] - ETA: 0s\n",
      "494/501 [============================>.] - ETA: 0s\n",
      "501/501 [==============================] - 0s 717us/step\n",
      "\n",
      " 1/66 [..............................] - ETA: 1s\n",
      "57/66 [========================>.....] - ETA: 0s\n",
      "66/66 [==============================] - 0s 890us/step\n",
      "\n",
      "Sequential Classification Report (Train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.68      0.56      8006\n",
      "           1       0.45      0.26      0.33      8006\n",
      "\n",
      "    accuracy                           0.47     16012\n",
      "   macro avg       0.46      0.47      0.44     16012\n",
      "weighted avg       0.46      0.47      0.44     16012\n",
      "\n",
      "\n",
      "Sequential Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.67      0.78      1994\n",
      "           1       0.03      0.19      0.04        90\n",
      "\n",
      "    accuracy                           0.65      2084\n",
      "   macro avg       0.49      0.43      0.41      2084\n",
      "weighted avg       0.91      0.65      0.75      2084\n",
      "\n",
      "\n",
      "Sequential Confusion Matrix (Test):\n",
      "[[1334  660]\n",
      " [  73   17]]\n",
      "\n",
      "Sequential Performance:\n",
      "Epoch 1/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 8:57 - loss: 0.6920 - accuracy: 0.3750\n",
      " 11/251 [>.............................] - ETA: 1s - loss: 0.6785 - accuracy: 0.5526  \n",
      " 21/251 [=>............................] - ETA: 1s - loss: 0.6697 - accuracy: 0.5707\n",
      " 31/251 [==>...........................] - ETA: 1s - loss: 0.6561 - accuracy: 0.5706\n",
      " 41/251 [===>..........................] - ETA: 1s - loss: 0.6526 - accuracy: 0.5774\n",
      " 51/251 [=====>........................] - ETA: 1s - loss: 0.6417 - accuracy: 0.5818\n",
      " 61/251 [======>.......................] - ETA: 0s - loss: 0.6381 - accuracy: 0.5978\n",
      " 71/251 [=======>......................] - ETA: 0s - loss: 0.6292 - accuracy: 0.6067\n",
      " 81/251 [========>.....................] - ETA: 0s - loss: 0.6236 - accuracy: 0.6167\n",
      " 91/251 [=========>....................] - ETA: 0s - loss: 0.6146 - accuracy: 0.6280\n",
      "101/251 [===========>..................] - ETA: 0s - loss: 0.6074 - accuracy: 0.6360\n",
      "111/251 [============>.................] - ETA: 0s - loss: 0.6030 - accuracy: 0.6421\n",
      "121/251 [=============>................] - ETA: 0s - loss: 0.5969 - accuracy: 0.6487\n",
      "131/251 [==============>...............] - ETA: 0s - loss: 0.5934 - accuracy: 0.6519\n",
      "141/251 [===============>..............] - ETA: 0s - loss: 0.5900 - accuracy: 0.6546\n",
      "151/251 [=================>............] - ETA: 0s - loss: 0.5862 - accuracy: 0.6596\n",
      "160/251 [==================>...........] - ETA: 0s - loss: 0.5868 - accuracy: 0.6607\n",
      "169/251 [===================>..........] - ETA: 0s - loss: 0.5849 - accuracy: 0.6645\n",
      "175/251 [===================>..........] - ETA: 0s - loss: 0.5821 - accuracy: 0.6685\n",
      "184/251 [====================>.........] - ETA: 0s - loss: 0.5799 - accuracy: 0.6716\n",
      "194/251 [======================>.......] - ETA: 0s - loss: 0.5772 - accuracy: 0.6745\n",
      "204/251 [=======================>......] - ETA: 0s - loss: 0.5745 - accuracy: 0.6768\n",
      "214/251 [========================>.....] - ETA: 0s - loss: 0.5712 - accuracy: 0.6800\n",
      "224/251 [=========================>....] - ETA: 0s - loss: 0.5695 - accuracy: 0.6831\n",
      "234/251 [==========================>...] - ETA: 0s - loss: 0.5664 - accuracy: 0.6863\n",
      "244/251 [============================>.] - ETA: 0s - loss: 0.5635 - accuracy: 0.6893\n",
      "251/251 [==============================] - 4s 8ms/step - loss: 0.5618 - accuracy: 0.6909 - val_loss: 0.4620 - val_accuracy: 0.8009\n",
      "Epoch 2/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 6s - loss: 0.5047 - accuracy: 0.7344\n",
      " 11/251 [>.............................] - ETA: 1s - loss: 0.5111 - accuracy: 0.7230\n",
      " 21/251 [=>............................] - ETA: 1s - loss: 0.4896 - accuracy: 0.7374\n",
      " 31/251 [==>...........................] - ETA: 1s - loss: 0.4863 - accuracy: 0.7455\n",
      " 41/251 [===>..........................] - ETA: 1s - loss: 0.4876 - accuracy: 0.7504\n",
      " 51/251 [=====>........................] - ETA: 1s - loss: 0.4937 - accuracy: 0.7491\n",
      " 61/251 [======>.......................] - ETA: 1s - loss: 0.4895 - accuracy: 0.7510\n",
      " 71/251 [=======>......................] - ETA: 0s - loss: 0.4916 - accuracy: 0.7469\n",
      " 80/251 [========>.....................] - ETA: 0s - loss: 0.4818 - accuracy: 0.7551\n",
      " 90/251 [=========>....................] - ETA: 0s - loss: 0.4771 - accuracy: 0.7584\n",
      " 99/251 [==========>...................] - ETA: 0s - loss: 0.4715 - accuracy: 0.7626\n",
      "109/251 [============>.................] - ETA: 0s - loss: 0.4669 - accuracy: 0.7650\n",
      "119/251 [=============>................] - ETA: 0s - loss: 0.4627 - accuracy: 0.7689\n",
      "129/251 [==============>...............] - ETA: 0s - loss: 0.4583 - accuracy: 0.7717\n",
      "138/251 [===============>..............] - ETA: 0s - loss: 0.4538 - accuracy: 0.7743\n",
      "148/251 [================>.............] - ETA: 0s - loss: 0.4508 - accuracy: 0.7773\n",
      "154/251 [=================>............] - ETA: 0s - loss: 0.4477 - accuracy: 0.7811\n",
      "164/251 [==================>...........] - ETA: 0s - loss: 0.4463 - accuracy: 0.7833\n",
      "173/251 [===================>..........] - ETA: 0s - loss: 0.4427 - accuracy: 0.7861\n",
      "183/251 [====================>.........] - ETA: 0s - loss: 0.4417 - accuracy: 0.7859\n",
      "193/251 [======================>.......] - ETA: 0s - loss: 0.4402 - accuracy: 0.7863\n",
      "203/251 [=======================>......] - ETA: 0s - loss: 0.4376 - accuracy: 0.7881\n",
      "212/251 [========================>.....] - ETA: 0s - loss: 0.4357 - accuracy: 0.7902\n",
      "222/251 [=========================>....] - ETA: 0s - loss: 0.4324 - accuracy: 0.7937\n",
      "232/251 [==========================>...] - ETA: 0s - loss: 0.4301 - accuracy: 0.7949\n",
      "242/251 [===========================>..] - ETA: 0s - loss: 0.4284 - accuracy: 0.7956\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 0.4262 - accuracy: 0.7971 - val_loss: 0.3409 - val_accuracy: 0.8354\n",
      "Epoch 3/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 6s - loss: 0.4239 - accuracy: 0.8125\n",
      " 11/251 [>.............................] - ETA: 1s - loss: 0.3445 - accuracy: 0.8523\n",
      " 21/251 [=>............................] - ETA: 1s - loss: 0.3449 - accuracy: 0.8497\n",
      " 30/251 [==>...........................] - ETA: 1s - loss: 0.3379 - accuracy: 0.8484\n",
      " 40/251 [===>..........................] - ETA: 1s - loss: 0.3288 - accuracy: 0.8489\n",
      " 50/251 [====>.........................] - ETA: 1s - loss: 0.3316 - accuracy: 0.8443\n",
      " 60/251 [======>.......................] - ETA: 1s - loss: 0.3237 - accuracy: 0.8524\n",
      " 70/251 [=======>......................] - ETA: 0s - loss: 0.3274 - accuracy: 0.8519\n",
      " 80/251 [========>.....................] - ETA: 0s - loss: 0.3251 - accuracy: 0.8546\n",
      " 89/251 [=========>....................] - ETA: 0s - loss: 0.3197 - accuracy: 0.8579\n",
      " 99/251 [==========>...................] - ETA: 0s - loss: 0.3180 - accuracy: 0.8598\n",
      "109/251 [============>.................] - ETA: 0s - loss: 0.3152 - accuracy: 0.8624\n",
      "119/251 [=============>................] - ETA: 0s - loss: 0.3094 - accuracy: 0.8673\n",
      "128/251 [==============>...............] - ETA: 0s - loss: 0.3114 - accuracy: 0.8645\n",
      "134/251 [===============>..............] - ETA: 0s - loss: 0.3124 - accuracy: 0.8643\n",
      "143/251 [================>.............] - ETA: 0s - loss: 0.3114 - accuracy: 0.8658\n",
      "153/251 [=================>............] - ETA: 0s - loss: 0.3126 - accuracy: 0.8643\n",
      "162/251 [==================>...........] - ETA: 0s - loss: 0.3138 - accuracy: 0.8638\n",
      "172/251 [===================>..........] - ETA: 0s - loss: 0.3113 - accuracy: 0.8650\n",
      "182/251 [====================>.........] - ETA: 0s - loss: 0.3098 - accuracy: 0.8666\n",
      "192/251 [=====================>........] - ETA: 0s - loss: 0.3115 - accuracy: 0.8657\n",
      "202/251 [=======================>......] - ETA: 0s - loss: 0.3081 - accuracy: 0.8669\n",
      "211/251 [========================>.....] - ETA: 0s - loss: 0.3072 - accuracy: 0.8680\n",
      "220/251 [=========================>....] - ETA: 0s - loss: 0.3072 - accuracy: 0.8685\n",
      "229/251 [==========================>...] - ETA: 0s - loss: 0.3064 - accuracy: 0.8692\n",
      "239/251 [===========================>..] - ETA: 0s - loss: 0.3052 - accuracy: 0.8693\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.3024 - accuracy: 0.8710\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 0.3020 - accuracy: 0.8715 - val_loss: 0.4271 - val_accuracy: 0.8013\n",
      "Epoch 4/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 5s - loss: 0.1787 - accuracy: 0.9219\n",
      " 11/251 [>.............................] - ETA: 1s - loss: 0.2550 - accuracy: 0.8892\n",
      " 20/251 [=>............................] - ETA: 1s - loss: 0.2718 - accuracy: 0.8797\n",
      " 29/251 [==>...........................] - ETA: 1s - loss: 0.2712 - accuracy: 0.8788\n",
      " 39/251 [===>..........................] - ETA: 1s - loss: 0.2667 - accuracy: 0.8838\n",
      " 49/251 [====>.........................] - ETA: 1s - loss: 0.2648 - accuracy: 0.8871\n",
      " 59/251 [======>.......................] - ETA: 1s - loss: 0.2741 - accuracy: 0.8811\n",
      " 68/251 [=======>......................] - ETA: 1s - loss: 0.2679 - accuracy: 0.8835\n",
      " 75/251 [=======>......................] - ETA: 1s - loss: 0.2673 - accuracy: 0.8852\n",
      " 80/251 [========>.....................] - ETA: 1s - loss: 0.2692 - accuracy: 0.8850\n",
      " 89/251 [=========>....................] - ETA: 0s - loss: 0.2694 - accuracy: 0.8848\n",
      " 98/251 [==========>...................] - ETA: 0s - loss: 0.2670 - accuracy: 0.8886\n",
      "107/251 [===========>..................] - ETA: 0s - loss: 0.2646 - accuracy: 0.8890\n",
      "117/251 [============>.................] - ETA: 0s - loss: 0.2610 - accuracy: 0.8916\n",
      "127/251 [==============>...............] - ETA: 0s - loss: 0.2586 - accuracy: 0.8932\n",
      "137/251 [===============>..............] - ETA: 0s - loss: 0.2589 - accuracy: 0.8920\n",
      "146/251 [================>.............] - ETA: 0s - loss: 0.2577 - accuracy: 0.8927\n",
      "156/251 [=================>............] - ETA: 0s - loss: 0.2581 - accuracy: 0.8924\n",
      "165/251 [==================>...........] - ETA: 0s - loss: 0.2561 - accuracy: 0.8936\n",
      "175/251 [===================>..........] - ETA: 0s - loss: 0.2554 - accuracy: 0.8933\n",
      "184/251 [====================>.........] - ETA: 0s - loss: 0.2568 - accuracy: 0.8925\n",
      "194/251 [======================>.......] - ETA: 0s - loss: 0.2559 - accuracy: 0.8929\n",
      "203/251 [=======================>......] - ETA: 0s - loss: 0.2550 - accuracy: 0.8939\n",
      "212/251 [========================>.....] - ETA: 0s - loss: 0.2534 - accuracy: 0.8946\n",
      "221/251 [=========================>....] - ETA: 0s - loss: 0.2529 - accuracy: 0.8942\n",
      "231/251 [==========================>...] - ETA: 0s - loss: 0.2534 - accuracy: 0.8947\n",
      "240/251 [===========================>..] - ETA: 0s - loss: 0.2513 - accuracy: 0.8957\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.2499 - accuracy: 0.8963\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 0.2493 - accuracy: 0.8965 - val_loss: 0.3363 - val_accuracy: 0.8546\n",
      "Epoch 5/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 5s - loss: 0.1225 - accuracy: 0.9688\n",
      " 10/251 [>.............................] - ETA: 1s - loss: 0.2465 - accuracy: 0.8969\n",
      " 16/251 [>.............................] - ETA: 1s - loss: 0.2484 - accuracy: 0.8955\n",
      " 25/251 [=>............................] - ETA: 1s - loss: 0.2404 - accuracy: 0.8969\n",
      " 34/251 [===>..........................] - ETA: 1s - loss: 0.2428 - accuracy: 0.8998\n",
      " 43/251 [====>.........................] - ETA: 1s - loss: 0.2341 - accuracy: 0.9037\n",
      " 52/251 [=====>........................] - ETA: 1s - loss: 0.2368 - accuracy: 0.9026\n",
      " 62/251 [======>.......................] - ETA: 1s - loss: 0.2322 - accuracy: 0.9060\n",
      " 71/251 [=======>......................] - ETA: 1s - loss: 0.2294 - accuracy: 0.9083\n",
      " 81/251 [========>.....................] - ETA: 1s - loss: 0.2279 - accuracy: 0.9092\n",
      " 91/251 [=========>....................] - ETA: 0s - loss: 0.2298 - accuracy: 0.9071\n",
      "101/251 [===========>..................] - ETA: 0s - loss: 0.2317 - accuracy: 0.9069\n",
      "110/251 [============>.................] - ETA: 0s - loss: 0.2331 - accuracy: 0.9076\n",
      "120/251 [=============>................] - ETA: 0s - loss: 0.2338 - accuracy: 0.9067\n",
      "130/251 [==============>...............] - ETA: 0s - loss: 0.2289 - accuracy: 0.9101\n",
      "140/251 [===============>..............] - ETA: 0s - loss: 0.2231 - accuracy: 0.9129\n",
      "149/251 [================>.............] - ETA: 0s - loss: 0.2255 - accuracy: 0.9117\n",
      "158/251 [=================>............] - ETA: 0s - loss: 0.2246 - accuracy: 0.9120\n",
      "167/251 [==================>...........] - ETA: 0s - loss: 0.2234 - accuracy: 0.9127\n",
      "176/251 [====================>.........] - ETA: 0s - loss: 0.2231 - accuracy: 0.9133\n",
      "185/251 [=====================>........] - ETA: 0s - loss: 0.2234 - accuracy: 0.9131\n",
      "194/251 [======================>.......] - ETA: 0s - loss: 0.2219 - accuracy: 0.9136\n",
      "204/251 [=======================>......] - ETA: 0s - loss: 0.2221 - accuracy: 0.9136\n",
      "213/251 [========================>.....] - ETA: 0s - loss: 0.2221 - accuracy: 0.9140\n",
      "219/251 [=========================>....] - ETA: 0s - loss: 0.2213 - accuracy: 0.9144\n",
      "228/251 [==========================>...] - ETA: 0s - loss: 0.2213 - accuracy: 0.9142\n",
      "238/251 [===========================>..] - ETA: 0s - loss: 0.2206 - accuracy: 0.9148\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.2187 - accuracy: 0.9158\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 0.2193 - accuracy: 0.9156 - val_loss: 0.2768 - val_accuracy: 0.8968\n",
      "Epoch 6/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 6s - loss: 0.2635 - accuracy: 0.9219\n",
      " 11/251 [>.............................] - ETA: 1s - loss: 0.1965 - accuracy: 0.9294\n",
      " 21/251 [=>............................] - ETA: 1s - loss: 0.2019 - accuracy: 0.9218\n",
      " 30/251 [==>...........................] - ETA: 1s - loss: 0.2021 - accuracy: 0.9245\n",
      " 39/251 [===>..........................] - ETA: 1s - loss: 0.2136 - accuracy: 0.9186\n",
      " 48/251 [====>.........................] - ETA: 1s - loss: 0.2129 - accuracy: 0.9192\n",
      " 57/251 [=====>........................] - ETA: 1s - loss: 0.2124 - accuracy: 0.9185\n",
      " 66/251 [======>.......................] - ETA: 1s - loss: 0.2090 - accuracy: 0.9190\n",
      " 75/251 [=======>......................] - ETA: 0s - loss: 0.2058 - accuracy: 0.9198\n",
      " 84/251 [=========>....................] - ETA: 0s - loss: 0.2191 - accuracy: 0.9159\n",
      " 93/251 [==========>...................] - ETA: 0s - loss: 0.2198 - accuracy: 0.9151\n",
      "102/251 [===========>..................] - ETA: 0s - loss: 0.2198 - accuracy: 0.9152\n",
      "111/251 [============>.................] - ETA: 0s - loss: 0.2195 - accuracy: 0.9153\n",
      "120/251 [=============>................] - ETA: 0s - loss: 0.2162 - accuracy: 0.9169\n",
      "125/251 [=============>................] - ETA: 0s - loss: 0.2164 - accuracy: 0.9170\n",
      "134/251 [===============>..............] - ETA: 0s - loss: 0.2151 - accuracy: 0.9179\n",
      "143/251 [================>.............] - ETA: 0s - loss: 0.2139 - accuracy: 0.9185\n",
      "152/251 [=================>............] - ETA: 0s - loss: 0.2114 - accuracy: 0.9194\n",
      "161/251 [==================>...........] - ETA: 0s - loss: 0.2137 - accuracy: 0.9184\n",
      "170/251 [===================>..........] - ETA: 0s - loss: 0.2141 - accuracy: 0.9185\n",
      "180/251 [====================>.........] - ETA: 0s - loss: 0.2133 - accuracy: 0.9189\n",
      "189/251 [=====================>........] - ETA: 0s - loss: 0.2144 - accuracy: 0.9183\n",
      "199/251 [======================>.......] - ETA: 0s - loss: 0.2124 - accuracy: 0.9197\n",
      "208/251 [=======================>......] - ETA: 0s - loss: 0.2118 - accuracy: 0.9200\n",
      "218/251 [=========================>....] - ETA: 0s - loss: 0.2093 - accuracy: 0.9209\n",
      "227/251 [==========================>...] - ETA: 0s - loss: 0.2074 - accuracy: 0.9217\n",
      "236/251 [===========================>..] - ETA: 0s - loss: 0.2079 - accuracy: 0.9217\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.2084 - accuracy: 0.9215\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 0.2084 - accuracy: 0.9216 - val_loss: 0.2756 - val_accuracy: 0.8863\n",
      "Epoch 7/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 6s - loss: 0.1775 - accuracy: 0.9375\n",
      " 10/251 [>.............................] - ETA: 1s - loss: 0.2386 - accuracy: 0.9109\n",
      " 19/251 [=>............................] - ETA: 1s - loss: 0.2199 - accuracy: 0.9243\n",
      " 25/251 [=>............................] - ETA: 1s - loss: 0.2129 - accuracy: 0.9262\n",
      " 34/251 [===>..........................] - ETA: 1s - loss: 0.2090 - accuracy: 0.9283\n",
      " 43/251 [====>.........................] - ETA: 1s - loss: 0.2102 - accuracy: 0.9273\n",
      " 52/251 [=====>........................] - ETA: 1s - loss: 0.2095 - accuracy: 0.9258\n",
      " 61/251 [======>.......................] - ETA: 1s - loss: 0.2089 - accuracy: 0.9249\n",
      " 71/251 [=======>......................] - ETA: 1s - loss: 0.2043 - accuracy: 0.9274\n",
      " 80/251 [========>.....................] - ETA: 1s - loss: 0.2051 - accuracy: 0.9268\n",
      " 89/251 [=========>....................] - ETA: 0s - loss: 0.2074 - accuracy: 0.9247\n",
      " 99/251 [==========>...................] - ETA: 0s - loss: 0.2059 - accuracy: 0.9261\n",
      "108/251 [===========>..................] - ETA: 0s - loss: 0.2049 - accuracy: 0.9268\n",
      "118/251 [=============>................] - ETA: 0s - loss: 0.2026 - accuracy: 0.9274\n",
      "127/251 [==============>...............] - ETA: 0s - loss: 0.1977 - accuracy: 0.9295\n",
      "136/251 [===============>..............] - ETA: 0s - loss: 0.1990 - accuracy: 0.9288\n",
      "146/251 [================>.............] - ETA: 0s - loss: 0.1996 - accuracy: 0.9279\n",
      "156/251 [=================>............] - ETA: 0s - loss: 0.2018 - accuracy: 0.9264\n",
      "162/251 [==================>...........] - ETA: 0s - loss: 0.2006 - accuracy: 0.9275\n",
      "171/251 [===================>..........] - ETA: 0s - loss: 0.1998 - accuracy: 0.9279\n",
      "181/251 [====================>.........] - ETA: 0s - loss: 0.1980 - accuracy: 0.9286\n",
      "187/251 [=====================>........] - ETA: 0s - loss: 0.1981 - accuracy: 0.9288\n",
      "196/251 [======================>.......] - ETA: 0s - loss: 0.1962 - accuracy: 0.9294\n",
      "205/251 [=======================>......] - ETA: 0s - loss: 0.1951 - accuracy: 0.9293\n",
      "214/251 [========================>.....] - ETA: 0s - loss: 0.1953 - accuracy: 0.9290\n",
      "223/251 [=========================>....] - ETA: 0s - loss: 0.1924 - accuracy: 0.9299\n",
      "232/251 [==========================>...] - ETA: 0s - loss: 0.1931 - accuracy: 0.9296\n",
      "241/251 [===========================>..] - ETA: 0s - loss: 0.1930 - accuracy: 0.9292\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.1935 - accuracy: 0.9291\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 0.1938 - accuracy: 0.9288 - val_loss: 0.2628 - val_accuracy: 0.9007\n",
      "Epoch 8/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 6s - loss: 0.1831 - accuracy: 0.9531\n",
      " 11/251 [>.............................] - ETA: 1s - loss: 0.1843 - accuracy: 0.9446\n",
      " 20/251 [=>............................] - ETA: 1s - loss: 0.1677 - accuracy: 0.9484\n",
      " 30/251 [==>...........................] - ETA: 1s - loss: 0.1916 - accuracy: 0.9307\n",
      " 39/251 [===>..........................] - ETA: 1s - loss: 0.2028 - accuracy: 0.9267\n",
      " 48/251 [====>.........................] - ETA: 1s - loss: 0.2059 - accuracy: 0.9232\n",
      " 58/251 [=====>........................] - ETA: 1s - loss: 0.2037 - accuracy: 0.9248\n",
      " 68/251 [=======>......................] - ETA: 1s - loss: 0.2006 - accuracy: 0.9272\n",
      " 74/251 [=======>......................] - ETA: 1s - loss: 0.1968 - accuracy: 0.9285\n",
      " 83/251 [========>.....................] - ETA: 0s - loss: 0.1959 - accuracy: 0.9291\n",
      " 93/251 [==========>...................] - ETA: 0s - loss: 0.1911 - accuracy: 0.9305\n",
      "103/251 [===========>..................] - ETA: 0s - loss: 0.1950 - accuracy: 0.9301\n",
      "112/251 [============>.................] - ETA: 0s - loss: 0.1920 - accuracy: 0.9303\n",
      "121/251 [=============>................] - ETA: 0s - loss: 0.1917 - accuracy: 0.9301\n",
      "130/251 [==============>...............] - ETA: 0s - loss: 0.1888 - accuracy: 0.9307\n",
      "140/251 [===============>..............] - ETA: 0s - loss: 0.1871 - accuracy: 0.9319\n",
      "149/251 [================>.............] - ETA: 0s - loss: 0.1867 - accuracy: 0.9320\n",
      "158/251 [=================>............] - ETA: 0s - loss: 0.1877 - accuracy: 0.9315\n",
      "168/251 [===================>..........] - ETA: 0s - loss: 0.1895 - accuracy: 0.9309\n",
      "177/251 [====================>.........] - ETA: 0s - loss: 0.1891 - accuracy: 0.9309\n",
      "186/251 [=====================>........] - ETA: 0s - loss: 0.1875 - accuracy: 0.9312\n",
      "195/251 [======================>.......] - ETA: 0s - loss: 0.1879 - accuracy: 0.9310\n",
      "204/251 [=======================>......] - ETA: 0s - loss: 0.1883 - accuracy: 0.9306\n",
      "213/251 [========================>.....] - ETA: 0s - loss: 0.1870 - accuracy: 0.9306\n",
      "222/251 [=========================>....] - ETA: 0s - loss: 0.1874 - accuracy: 0.9306\n",
      "228/251 [==========================>...] - ETA: 0s - loss: 0.1864 - accuracy: 0.9313\n",
      "237/251 [===========================>..] - ETA: 0s - loss: 0.1854 - accuracy: 0.9315\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.1832 - accuracy: 0.9324\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 0.1842 - accuracy: 0.9320 - val_loss: 0.2977 - val_accuracy: 0.8935\n",
      "Epoch 9/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 6s - loss: 0.0522 - accuracy: 1.0000\n",
      " 10/251 [>.............................] - ETA: 1s - loss: 0.1491 - accuracy: 0.9422\n",
      " 19/251 [=>............................] - ETA: 1s - loss: 0.1626 - accuracy: 0.9391\n",
      " 28/251 [==>...........................] - ETA: 1s - loss: 0.1684 - accuracy: 0.9414\n",
      " 37/251 [===>..........................] - ETA: 1s - loss: 0.1662 - accuracy: 0.9417\n",
      " 47/251 [====>.........................] - ETA: 1s - loss: 0.1735 - accuracy: 0.9365\n",
      " 56/251 [=====>........................] - ETA: 1s - loss: 0.1695 - accuracy: 0.9372\n",
      " 64/251 [======>.......................] - ETA: 1s - loss: 0.1652 - accuracy: 0.9392\n",
      " 72/251 [=======>......................] - ETA: 1s - loss: 0.1659 - accuracy: 0.9395\n",
      " 77/251 [========>.....................] - ETA: 1s - loss: 0.1634 - accuracy: 0.9405\n",
      " 86/251 [=========>....................] - ETA: 1s - loss: 0.1618 - accuracy: 0.9408\n",
      " 95/251 [==========>...................] - ETA: 0s - loss: 0.1609 - accuracy: 0.9410\n",
      "104/251 [===========>..................] - ETA: 0s - loss: 0.1656 - accuracy: 0.9395\n",
      "113/251 [============>.................] - ETA: 0s - loss: 0.1669 - accuracy: 0.9385\n",
      "123/251 [=============>................] - ETA: 0s - loss: 0.1673 - accuracy: 0.9378\n",
      "132/251 [==============>...............] - ETA: 0s - loss: 0.1668 - accuracy: 0.9384\n",
      "142/251 [===============>..............] - ETA: 0s - loss: 0.1673 - accuracy: 0.9378\n",
      "152/251 [=================>............] - ETA: 0s - loss: 0.1668 - accuracy: 0.9381\n",
      "161/251 [==================>...........] - ETA: 0s - loss: 0.1664 - accuracy: 0.9387\n",
      "170/251 [===================>..........] - ETA: 0s - loss: 0.1674 - accuracy: 0.9384\n",
      "179/251 [====================>.........] - ETA: 0s - loss: 0.1675 - accuracy: 0.9387\n",
      "188/251 [=====================>........] - ETA: 0s - loss: 0.1682 - accuracy: 0.9382\n",
      "197/251 [======================>.......] - ETA: 0s - loss: 0.1685 - accuracy: 0.9380\n",
      "206/251 [=======================>......] - ETA: 0s - loss: 0.1675 - accuracy: 0.9379\n",
      "215/251 [========================>.....] - ETA: 0s - loss: 0.1663 - accuracy: 0.9384\n",
      "220/251 [=========================>....] - ETA: 0s - loss: 0.1665 - accuracy: 0.9383\n",
      "229/251 [==========================>...] - ETA: 0s - loss: 0.1674 - accuracy: 0.9376\n",
      "239/251 [===========================>..] - ETA: 0s - loss: 0.1672 - accuracy: 0.9380\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.1690 - accuracy: 0.9374\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 0.1689 - accuracy: 0.9374 - val_loss: 0.2160 - val_accuracy: 0.9213\n",
      "Epoch 10/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 6s - loss: 0.2506 - accuracy: 0.9062\n",
      " 12/251 [>.............................] - ETA: 1s - loss: 0.1824 - accuracy: 0.9297\n",
      " 22/251 [=>............................] - ETA: 1s - loss: 0.1790 - accuracy: 0.9292\n",
      " 31/251 [==>...........................] - ETA: 1s - loss: 0.1690 - accuracy: 0.9332\n",
      " 41/251 [===>..........................] - ETA: 1s - loss: 0.1653 - accuracy: 0.9351\n",
      " 50/251 [====>.........................] - ETA: 1s - loss: 0.1674 - accuracy: 0.9361\n",
      " 59/251 [======>.......................] - ETA: 1s - loss: 0.1649 - accuracy: 0.9372\n",
      " 68/251 [=======>......................] - ETA: 0s - loss: 0.1665 - accuracy: 0.9363\n",
      " 77/251 [========>.....................] - ETA: 0s - loss: 0.1629 - accuracy: 0.9381\n",
      " 87/251 [=========>....................] - ETA: 0s - loss: 0.1633 - accuracy: 0.9389\n",
      " 93/251 [==========>...................] - ETA: 0s - loss: 0.1648 - accuracy: 0.9392\n",
      "102/251 [===========>..................] - ETA: 0s - loss: 0.1658 - accuracy: 0.9393\n",
      "111/251 [============>.................] - ETA: 0s - loss: 0.1627 - accuracy: 0.9410\n",
      "120/251 [=============>................] - ETA: 0s - loss: 0.1632 - accuracy: 0.9401\n",
      "129/251 [==============>...............] - ETA: 0s - loss: 0.1635 - accuracy: 0.9402\n",
      "138/251 [===============>..............] - ETA: 0s - loss: 0.1640 - accuracy: 0.9399\n",
      "147/251 [================>.............] - ETA: 0s - loss: 0.1645 - accuracy: 0.9394\n",
      "156/251 [=================>............] - ETA: 0s - loss: 0.1649 - accuracy: 0.9389\n",
      "165/251 [==================>...........] - ETA: 0s - loss: 0.1641 - accuracy: 0.9392\n",
      "174/251 [===================>..........] - ETA: 0s - loss: 0.1647 - accuracy: 0.9390\n",
      "183/251 [====================>.........] - ETA: 0s - loss: 0.1656 - accuracy: 0.9389\n",
      "192/251 [=====================>........] - ETA: 0s - loss: 0.1657 - accuracy: 0.9385\n",
      "201/251 [=======================>......] - ETA: 0s - loss: 0.1656 - accuracy: 0.9387\n",
      "210/251 [========================>.....] - ETA: 0s - loss: 0.1637 - accuracy: 0.9394\n",
      "219/251 [=========================>....] - ETA: 0s - loss: 0.1626 - accuracy: 0.9399\n",
      "225/251 [=========================>....] - ETA: 0s - loss: 0.1625 - accuracy: 0.9398\n",
      "234/251 [==========================>...] - ETA: 0s - loss: 0.1628 - accuracy: 0.9398\n",
      "243/251 [============================>.] - ETA: 0s - loss: 0.1620 - accuracy: 0.9404\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 0.1625 - accuracy: 0.9401 - val_loss: 0.2306 - val_accuracy: 0.9155\n",
      "\n",
      "  1/501 [..............................] - ETA: 3:25\n",
      " 29/501 [>.............................] - ETA: 0s  \n",
      " 58/501 [==>...........................] - ETA: 0s\n",
      " 85/501 [====>.........................] - ETA: 0s\n",
      "114/501 [=====>........................] - ETA: 0s\n",
      "143/501 [=======>......................] - ETA: 0s\n",
      "171/501 [=========>....................] - ETA: 0s\n",
      "199/501 [==========>...................] - ETA: 0s\n",
      "225/501 [============>.................] - ETA: 0s\n",
      "253/501 [==============>...............] - ETA: 0s\n",
      "280/501 [===============>..............] - ETA: 0s\n",
      "293/501 [================>.............] - ETA: 0s\n",
      "320/501 [==================>...........] - ETA: 0s\n",
      "347/501 [===================>..........] - ETA: 0s\n",
      "378/501 [=====================>........] - ETA: 0s\n",
      "406/501 [=======================>......] - ETA: 0s\n",
      "434/501 [========================>.....] - ETA: 0s\n",
      "460/501 [==========================>...] - ETA: 0s\n",
      "488/501 [============================>.] - ETA: 0s\n",
      "501/501 [==============================] - 1s 2ms/step\n",
      "\n",
      " 1/66 [..............................] - ETA: 1s\n",
      "29/66 [============>.................] - ETA: 0s\n",
      "55/66 [========================>.....] - ETA: 0s\n",
      "66/66 [==============================] - 0s 2ms/step\n",
      "\n",
      "Sequential Classification Report (Train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.73      0.54      8006\n",
      "           1       0.09      0.03      0.04      8006\n",
      "\n",
      "    accuracy                           0.38     16012\n",
      "   macro avg       0.26      0.38      0.29     16012\n",
      "weighted avg       0.26      0.38      0.29     16012\n",
      "\n",
      "\n",
      "Sequential Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.73      0.82      1994\n",
      "           1       0.00      0.01      0.00        90\n",
      "\n",
      "    accuracy                           0.70      2084\n",
      "   macro avg       0.47      0.37      0.41      2084\n",
      "weighted avg       0.90      0.70      0.79      2084\n",
      "\n",
      "\n",
      "Sequential Confusion Matrix (Test):\n",
      "[[1459  535]\n",
      " [  89    1]]\n",
      "\n",
      "Sequential Performance:\n",
      "Epoch 1/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 9:25 - loss: 0.6863 - accuracy: 0.6875\n",
      " 12/251 [>.............................] - ETA: 1s - loss: 0.6863 - accuracy: 0.5599  \n",
      " 19/251 [=>............................] - ETA: 1s - loss: 0.6768 - accuracy: 0.5970\n",
      " 30/251 [==>...........................] - ETA: 1s - loss: 0.6655 - accuracy: 0.6198\n",
      " 41/251 [===>..........................] - ETA: 1s - loss: 0.6479 - accuracy: 0.6460\n",
      " 51/251 [=====>........................] - ETA: 1s - loss: 0.6335 - accuracy: 0.6578\n",
      " 62/251 [======>.......................] - ETA: 0s - loss: 0.6149 - accuracy: 0.6676\n",
      " 73/251 [=======>......................] - ETA: 0s - loss: 0.6167 - accuracy: 0.6584\n",
      " 84/251 [=========>....................] - ETA: 0s - loss: 0.6134 - accuracy: 0.6548\n",
      " 95/251 [==========>...................] - ETA: 0s - loss: 0.5998 - accuracy: 0.6673\n",
      "106/251 [===========>..................] - ETA: 0s - loss: 0.5933 - accuracy: 0.6704\n",
      "113/251 [============>.................] - ETA: 0s - loss: 0.5889 - accuracy: 0.6734\n",
      "124/251 [=============>................] - ETA: 0s - loss: 0.5821 - accuracy: 0.6807\n",
      "135/251 [===============>..............] - ETA: 0s - loss: 0.5760 - accuracy: 0.6858\n",
      "146/251 [================>.............] - ETA: 0s - loss: 0.5697 - accuracy: 0.6914\n",
      "157/251 [=================>............] - ETA: 0s - loss: 0.5624 - accuracy: 0.6972\n",
      "167/251 [==================>...........] - ETA: 0s - loss: 0.5583 - accuracy: 0.7011\n",
      "177/251 [====================>.........] - ETA: 0s - loss: 0.5542 - accuracy: 0.7069\n",
      "187/251 [=====================>........] - ETA: 0s - loss: 0.5504 - accuracy: 0.7086\n",
      "197/251 [======================>.......] - ETA: 0s - loss: 0.5461 - accuracy: 0.7113\n",
      "207/251 [=======================>......] - ETA: 0s - loss: 0.5416 - accuracy: 0.7138\n",
      "217/251 [========================>.....] - ETA: 0s - loss: 0.5372 - accuracy: 0.7171\n",
      "227/251 [==========================>...] - ETA: 0s - loss: 0.5344 - accuracy: 0.7190\n",
      "237/251 [===========================>..] - ETA: 0s - loss: 0.5341 - accuracy: 0.7190\n",
      "244/251 [============================>.] - ETA: 0s - loss: 0.5318 - accuracy: 0.7210\n",
      "251/251 [==============================] - 4s 7ms/step - loss: 0.5308 - accuracy: 0.7221 - val_loss: 0.5349 - val_accuracy: 0.7356\n",
      "Epoch 2/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 7s - loss: 0.4448 - accuracy: 0.7969\n",
      " 11/251 [>.............................] - ETA: 1s - loss: 0.4436 - accuracy: 0.7912\n",
      " 21/251 [=>............................] - ETA: 1s - loss: 0.4310 - accuracy: 0.8073\n",
      " 31/251 [==>...........................] - ETA: 1s - loss: 0.4359 - accuracy: 0.7969\n",
      " 42/251 [====>.........................] - ETA: 1s - loss: 0.4446 - accuracy: 0.7961\n",
      " 53/251 [=====>........................] - ETA: 0s - loss: 0.4360 - accuracy: 0.8013\n",
      " 64/251 [======>.......................] - ETA: 0s - loss: 0.4345 - accuracy: 0.8000\n",
      " 74/251 [=======>......................] - ETA: 0s - loss: 0.4381 - accuracy: 0.7920\n",
      " 84/251 [=========>....................] - ETA: 0s - loss: 0.4355 - accuracy: 0.7956\n",
      " 95/251 [==========>...................] - ETA: 0s - loss: 0.4344 - accuracy: 0.7985\n",
      "102/251 [===========>..................] - ETA: 0s - loss: 0.4325 - accuracy: 0.7990\n",
      "111/251 [============>.................] - ETA: 0s - loss: 0.4311 - accuracy: 0.8004\n",
      "122/251 [=============>................] - ETA: 0s - loss: 0.4273 - accuracy: 0.8017\n",
      "133/251 [==============>...............] - ETA: 0s - loss: 0.4258 - accuracy: 0.8040\n",
      "143/251 [================>.............] - ETA: 0s - loss: 0.4249 - accuracy: 0.8053\n",
      "153/251 [=================>............] - ETA: 0s - loss: 0.4239 - accuracy: 0.8038\n",
      "164/251 [==================>...........] - ETA: 0s - loss: 0.4221 - accuracy: 0.8043\n",
      "174/251 [===================>..........] - ETA: 0s - loss: 0.4231 - accuracy: 0.8029\n",
      "184/251 [====================>.........] - ETA: 0s - loss: 0.4207 - accuracy: 0.8041\n",
      "194/251 [======================>.......] - ETA: 0s - loss: 0.4177 - accuracy: 0.8052\n",
      "204/251 [=======================>......] - ETA: 0s - loss: 0.4143 - accuracy: 0.8063\n",
      "215/251 [========================>.....] - ETA: 0s - loss: 0.4110 - accuracy: 0.8084\n",
      "226/251 [==========================>...] - ETA: 0s - loss: 0.4073 - accuracy: 0.8118\n",
      "232/251 [==========================>...] - ETA: 0s - loss: 0.4057 - accuracy: 0.8125\n",
      "242/251 [===========================>..] - ETA: 0s - loss: 0.4045 - accuracy: 0.8136\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 0.4007 - accuracy: 0.8155 - val_loss: 0.5289 - val_accuracy: 0.8004\n",
      "Epoch 3/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 6s - loss: 0.1779 - accuracy: 0.9375\n",
      " 11/251 [>.............................] - ETA: 1s - loss: 0.3767 - accuracy: 0.8580\n",
      " 22/251 [=>............................] - ETA: 1s - loss: 0.3643 - accuracy: 0.8494\n",
      " 32/251 [==>...........................] - ETA: 1s - loss: 0.3676 - accuracy: 0.8506\n",
      " 42/251 [====>.........................] - ETA: 1s - loss: 0.3557 - accuracy: 0.8575\n",
      " 53/251 [=====>........................] - ETA: 0s - loss: 0.3490 - accuracy: 0.8603\n",
      " 63/251 [======>.......................] - ETA: 0s - loss: 0.3356 - accuracy: 0.8676\n",
      " 72/251 [=======>......................] - ETA: 0s - loss: 0.3343 - accuracy: 0.8690\n",
      " 82/251 [========>.....................] - ETA: 0s - loss: 0.3415 - accuracy: 0.8661\n",
      " 89/251 [=========>....................] - ETA: 0s - loss: 0.3443 - accuracy: 0.8625\n",
      " 98/251 [==========>...................] - ETA: 0s - loss: 0.3438 - accuracy: 0.8601\n",
      "106/251 [===========>..................] - ETA: 0s - loss: 0.3479 - accuracy: 0.8575\n",
      "113/251 [============>.................] - ETA: 0s - loss: 0.3444 - accuracy: 0.8610\n",
      "122/251 [=============>................] - ETA: 0s - loss: 0.3477 - accuracy: 0.8599\n",
      "132/251 [==============>...............] - ETA: 0s - loss: 0.3500 - accuracy: 0.8568\n",
      "142/251 [===============>..............] - ETA: 0s - loss: 0.3486 - accuracy: 0.8568\n",
      "152/251 [=================>............] - ETA: 0s - loss: 0.3486 - accuracy: 0.8575\n",
      "162/251 [==================>...........] - ETA: 0s - loss: 0.3459 - accuracy: 0.8590\n",
      "172/251 [===================>..........] - ETA: 0s - loss: 0.3442 - accuracy: 0.8595\n",
      "182/251 [====================>.........] - ETA: 0s - loss: 0.3411 - accuracy: 0.8612\n",
      "191/251 [=====================>........] - ETA: 0s - loss: 0.3402 - accuracy: 0.8622\n",
      "201/251 [=======================>......] - ETA: 0s - loss: 0.3367 - accuracy: 0.8640\n",
      "208/251 [=======================>......] - ETA: 0s - loss: 0.3368 - accuracy: 0.8633\n",
      "217/251 [========================>.....] - ETA: 0s - loss: 0.3380 - accuracy: 0.8622\n",
      "227/251 [==========================>...] - ETA: 0s - loss: 0.3364 - accuracy: 0.8620\n",
      "237/251 [===========================>..] - ETA: 0s - loss: 0.3357 - accuracy: 0.8619\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.3338 - accuracy: 0.8628\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 0.3318 - accuracy: 0.8636 - val_loss: 0.2808 - val_accuracy: 0.8848\n",
      "Epoch 4/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 7s - loss: 0.2803 - accuracy: 0.9062\n",
      " 11/251 [>.............................] - ETA: 1s - loss: 0.3104 - accuracy: 0.8821\n",
      " 21/251 [=>............................] - ETA: 1s - loss: 0.2843 - accuracy: 0.8854\n",
      " 32/251 [==>...........................] - ETA: 1s - loss: 0.2959 - accuracy: 0.8877\n",
      " 43/251 [====>.........................] - ETA: 1s - loss: 0.3045 - accuracy: 0.8797\n",
      " 49/251 [====>.........................] - ETA: 1s - loss: 0.3073 - accuracy: 0.8788\n",
      " 59/251 [======>.......................] - ETA: 1s - loss: 0.3055 - accuracy: 0.8806\n",
      " 69/251 [=======>......................] - ETA: 0s - loss: 0.2956 - accuracy: 0.8845\n",
      " 80/251 [========>.....................] - ETA: 0s - loss: 0.3016 - accuracy: 0.8805\n",
      " 90/251 [=========>....................] - ETA: 0s - loss: 0.2978 - accuracy: 0.8804\n",
      "101/251 [===========>..................] - ETA: 0s - loss: 0.2971 - accuracy: 0.8801\n",
      "111/251 [============>.................] - ETA: 0s - loss: 0.2939 - accuracy: 0.8819\n",
      "120/251 [=============>................] - ETA: 0s - loss: 0.2914 - accuracy: 0.8828\n",
      "131/251 [==============>...............] - ETA: 0s - loss: 0.2920 - accuracy: 0.8811\n",
      "142/251 [===============>..............] - ETA: 0s - loss: 0.2916 - accuracy: 0.8815\n",
      "148/251 [================>.............] - ETA: 0s - loss: 0.2911 - accuracy: 0.8809\n",
      "158/251 [=================>............] - ETA: 0s - loss: 0.2933 - accuracy: 0.8805\n",
      "168/251 [===================>..........] - ETA: 0s - loss: 0.2923 - accuracy: 0.8819\n",
      "178/251 [====================>.........] - ETA: 0s - loss: 0.2918 - accuracy: 0.8818\n",
      "189/251 [=====================>........] - ETA: 0s - loss: 0.2921 - accuracy: 0.8816\n",
      "199/251 [======================>.......] - ETA: 0s - loss: 0.2926 - accuracy: 0.8816\n",
      "209/251 [=======================>......] - ETA: 0s - loss: 0.2922 - accuracy: 0.8823\n",
      "219/251 [=========================>....] - ETA: 0s - loss: 0.2904 - accuracy: 0.8834\n",
      "229/251 [==========================>...] - ETA: 0s - loss: 0.2904 - accuracy: 0.8830\n",
      "240/251 [===========================>..] - ETA: 0s - loss: 0.2887 - accuracy: 0.8841\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.2862 - accuracy: 0.8851\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 0.2862 - accuracy: 0.8850 - val_loss: 0.4155 - val_accuracy: 0.8196\n",
      "Epoch 5/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 11s - loss: 0.1579 - accuracy: 0.9375\n",
      " 11/251 [>.............................] - ETA: 1s - loss: 0.2804 - accuracy: 0.8906 \n",
      " 21/251 [=>............................] - ETA: 1s - loss: 0.2779 - accuracy: 0.8921\n",
      " 30/251 [==>...........................] - ETA: 1s - loss: 0.2612 - accuracy: 0.9016\n",
      " 40/251 [===>..........................] - ETA: 1s - loss: 0.2714 - accuracy: 0.8945\n",
      " 51/251 [=====>........................] - ETA: 1s - loss: 0.2735 - accuracy: 0.8943\n",
      " 62/251 [======>.......................] - ETA: 0s - loss: 0.2741 - accuracy: 0.8942\n",
      " 72/251 [=======>......................] - ETA: 0s - loss: 0.2753 - accuracy: 0.8915\n",
      " 83/251 [========>.....................] - ETA: 0s - loss: 0.2706 - accuracy: 0.8941\n",
      " 94/251 [==========>...................] - ETA: 0s - loss: 0.2765 - accuracy: 0.8905\n",
      "104/251 [===========>..................] - ETA: 0s - loss: 0.2683 - accuracy: 0.8946\n",
      "111/251 [============>.................] - ETA: 0s - loss: 0.2671 - accuracy: 0.8953\n",
      "121/251 [=============>................] - ETA: 0s - loss: 0.2659 - accuracy: 0.8953\n",
      "131/251 [==============>...............] - ETA: 0s - loss: 0.2641 - accuracy: 0.8963\n",
      "141/251 [===============>..............] - ETA: 0s - loss: 0.2651 - accuracy: 0.8960\n",
      "152/251 [=================>............] - ETA: 0s - loss: 0.2651 - accuracy: 0.8956\n",
      "162/251 [==================>...........] - ETA: 0s - loss: 0.2682 - accuracy: 0.8935\n",
      "172/251 [===================>..........] - ETA: 0s - loss: 0.2670 - accuracy: 0.8938\n",
      "182/251 [====================>.........] - ETA: 0s - loss: 0.2667 - accuracy: 0.8942\n",
      "192/251 [=====================>........] - ETA: 0s - loss: 0.2654 - accuracy: 0.8951\n",
      "202/251 [=======================>......] - ETA: 0s - loss: 0.2644 - accuracy: 0.8953\n",
      "212/251 [========================>.....] - ETA: 0s - loss: 0.2634 - accuracy: 0.8958\n",
      "222/251 [=========================>....] - ETA: 0s - loss: 0.2630 - accuracy: 0.8957\n",
      "229/251 [==========================>...] - ETA: 0s - loss: 0.2627 - accuracy: 0.8960\n",
      "239/251 [===========================>..] - ETA: 0s - loss: 0.2618 - accuracy: 0.8968\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.2588 - accuracy: 0.8985\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 0.2581 - accuracy: 0.8988 - val_loss: 0.2736 - val_accuracy: 0.8949\n",
      "Epoch 6/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 7s - loss: 0.3238 - accuracy: 0.8594\n",
      " 11/251 [>.............................] - ETA: 1s - loss: 0.2334 - accuracy: 0.9034\n",
      " 22/251 [=>............................] - ETA: 1s - loss: 0.2371 - accuracy: 0.9070\n",
      " 32/251 [==>...........................] - ETA: 1s - loss: 0.2261 - accuracy: 0.9150\n",
      " 42/251 [====>.........................] - ETA: 1s - loss: 0.2080 - accuracy: 0.9237\n",
      " 52/251 [=====>........................] - ETA: 1s - loss: 0.2177 - accuracy: 0.9198\n",
      " 58/251 [=====>........................] - ETA: 1s - loss: 0.2176 - accuracy: 0.9197\n",
      " 67/251 [=======>......................] - ETA: 1s - loss: 0.2170 - accuracy: 0.9198\n",
      " 78/251 [========>.....................] - ETA: 0s - loss: 0.2142 - accuracy: 0.9195\n",
      " 89/251 [=========>....................] - ETA: 0s - loss: 0.2119 - accuracy: 0.9196\n",
      " 99/251 [==========>...................] - ETA: 0s - loss: 0.2191 - accuracy: 0.9159\n",
      "109/251 [============>.................] - ETA: 0s - loss: 0.2212 - accuracy: 0.9157\n",
      "119/251 [=============>................] - ETA: 0s - loss: 0.2240 - accuracy: 0.9154\n",
      "129/251 [==============>...............] - ETA: 0s - loss: 0.2237 - accuracy: 0.9158\n",
      "139/251 [===============>..............] - ETA: 0s - loss: 0.2225 - accuracy: 0.9173\n",
      "149/251 [================>.............] - ETA: 0s - loss: 0.2220 - accuracy: 0.9177\n",
      "159/251 [==================>...........] - ETA: 0s - loss: 0.2213 - accuracy: 0.9180\n",
      "165/251 [==================>...........] - ETA: 0s - loss: 0.2237 - accuracy: 0.9166\n",
      "175/251 [===================>..........] - ETA: 0s - loss: 0.2230 - accuracy: 0.9166\n",
      "185/251 [=====================>........] - ETA: 0s - loss: 0.2214 - accuracy: 0.9175\n",
      "195/251 [======================>.......] - ETA: 0s - loss: 0.2203 - accuracy: 0.9177\n",
      "205/251 [=======================>......] - ETA: 0s - loss: 0.2196 - accuracy: 0.9179\n",
      "214/251 [========================>.....] - ETA: 0s - loss: 0.2216 - accuracy: 0.9165\n",
      "223/251 [=========================>....] - ETA: 0s - loss: 0.2213 - accuracy: 0.9163\n",
      "233/251 [==========================>...] - ETA: 0s - loss: 0.2215 - accuracy: 0.9162\n",
      "243/251 [============================>.] - ETA: 0s - loss: 0.2222 - accuracy: 0.9159\n",
      "251/251 [==============================] - 1s 6ms/step - loss: 0.2231 - accuracy: 0.9154 - val_loss: 0.2399 - val_accuracy: 0.9074\n",
      "Epoch 7/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 10s - loss: 0.2123 - accuracy: 0.8906\n",
      "  9/251 [>.............................] - ETA: 1s - loss: 0.2142 - accuracy: 0.9132 \n",
      " 19/251 [=>............................] - ETA: 1s - loss: 0.2169 - accuracy: 0.9153\n",
      " 29/251 [==>...........................] - ETA: 1s - loss: 0.2172 - accuracy: 0.9197\n",
      " 39/251 [===>..........................] - ETA: 1s - loss: 0.2206 - accuracy: 0.9179\n",
      " 48/251 [====>.........................] - ETA: 1s - loss: 0.2126 - accuracy: 0.9206\n",
      " 58/251 [=====>........................] - ETA: 1s - loss: 0.2117 - accuracy: 0.9235\n",
      " 68/251 [=======>......................] - ETA: 0s - loss: 0.2124 - accuracy: 0.9237\n",
      " 78/251 [========>.....................] - ETA: 0s - loss: 0.2131 - accuracy: 0.9235\n",
      " 88/251 [=========>....................] - ETA: 0s - loss: 0.2133 - accuracy: 0.9226\n",
      " 97/251 [==========>...................] - ETA: 0s - loss: 0.2102 - accuracy: 0.9228\n",
      "104/251 [===========>..................] - ETA: 0s - loss: 0.2096 - accuracy: 0.9228\n",
      "113/251 [============>.................] - ETA: 0s - loss: 0.2094 - accuracy: 0.9224\n",
      "123/251 [=============>................] - ETA: 0s - loss: 0.2079 - accuracy: 0.9224\n",
      "133/251 [==============>...............] - ETA: 0s - loss: 0.2067 - accuracy: 0.9229\n",
      "143/251 [================>.............] - ETA: 0s - loss: 0.2065 - accuracy: 0.9234\n",
      "152/251 [=================>............] - ETA: 0s - loss: 0.2056 - accuracy: 0.9241\n",
      "161/251 [==================>...........] - ETA: 0s - loss: 0.2042 - accuracy: 0.9247\n",
      "170/251 [===================>..........] - ETA: 0s - loss: 0.2047 - accuracy: 0.9243\n",
      "180/251 [====================>.........] - ETA: 0s - loss: 0.2041 - accuracy: 0.9244\n",
      "190/251 [=====================>........] - ETA: 0s - loss: 0.2038 - accuracy: 0.9249\n",
      "197/251 [======================>.......] - ETA: 0s - loss: 0.2065 - accuracy: 0.9235\n",
      "207/251 [=======================>......] - ETA: 0s - loss: 0.2078 - accuracy: 0.9228\n",
      "217/251 [========================>.....] - ETA: 0s - loss: 0.2098 - accuracy: 0.9217\n",
      "226/251 [==========================>...] - ETA: 0s - loss: 0.2096 - accuracy: 0.9221\n",
      "236/251 [===========================>..] - ETA: 0s - loss: 0.2110 - accuracy: 0.9211\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.2115 - accuracy: 0.9214\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 0.2108 - accuracy: 0.9216 - val_loss: 0.2595 - val_accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 5s - loss: 0.1371 - accuracy: 0.9688\n",
      " 10/251 [>.............................] - ETA: 1s - loss: 0.2140 - accuracy: 0.9250\n",
      " 20/251 [=>............................] - ETA: 1s - loss: 0.2091 - accuracy: 0.9289\n",
      " 27/251 [==>...........................] - ETA: 1s - loss: 0.2035 - accuracy: 0.9282\n",
      " 37/251 [===>..........................] - ETA: 1s - loss: 0.1996 - accuracy: 0.9278\n",
      " 47/251 [====>.........................] - ETA: 1s - loss: 0.1920 - accuracy: 0.9325\n",
      " 57/251 [=====>........................] - ETA: 1s - loss: 0.1954 - accuracy: 0.9301\n",
      " 67/251 [=======>......................] - ETA: 1s - loss: 0.1915 - accuracy: 0.9307\n",
      " 77/251 [========>.....................] - ETA: 0s - loss: 0.1872 - accuracy: 0.9341\n",
      " 87/251 [=========>....................] - ETA: 0s - loss: 0.1866 - accuracy: 0.9341\n",
      " 97/251 [==========>...................] - ETA: 0s - loss: 0.1924 - accuracy: 0.9309\n",
      "107/251 [===========>..................] - ETA: 0s - loss: 0.1897 - accuracy: 0.9312\n",
      "117/251 [============>.................] - ETA: 0s - loss: 0.1897 - accuracy: 0.9320\n",
      "127/251 [==============>...............] - ETA: 0s - loss: 0.1886 - accuracy: 0.9322\n",
      "134/251 [===============>..............] - ETA: 0s - loss: 0.1888 - accuracy: 0.9317\n",
      "143/251 [================>.............] - ETA: 0s - loss: 0.1862 - accuracy: 0.9328\n",
      "153/251 [=================>............] - ETA: 0s - loss: 0.1875 - accuracy: 0.9326\n",
      "163/251 [==================>...........] - ETA: 0s - loss: 0.1887 - accuracy: 0.9319\n",
      "172/251 [===================>..........] - ETA: 0s - loss: 0.1878 - accuracy: 0.9321\n",
      "177/251 [====================>.........] - ETA: 0s - loss: 0.1890 - accuracy: 0.9314\n",
      "184/251 [====================>.........] - ETA: 0s - loss: 0.1893 - accuracy: 0.9308\n",
      "191/251 [=====================>........] - ETA: 0s - loss: 0.1897 - accuracy: 0.9306\n",
      "200/251 [======================>.......] - ETA: 0s - loss: 0.1908 - accuracy: 0.9299\n",
      "208/251 [=======================>......] - ETA: 0s - loss: 0.1910 - accuracy: 0.9297\n",
      "216/251 [========================>.....] - ETA: 0s - loss: 0.1911 - accuracy: 0.9301\n",
      "225/251 [=========================>....] - ETA: 0s - loss: 0.1923 - accuracy: 0.9295\n",
      "235/251 [===========================>..] - ETA: 0s - loss: 0.1916 - accuracy: 0.9296\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.1906 - accuracy: 0.9298\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 0.1926 - accuracy: 0.9286 - val_loss: 0.2528 - val_accuracy: 0.8978\n",
      "Epoch 9/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 6s - loss: 0.1553 - accuracy: 0.9375\n",
      " 10/251 [>.............................] - ETA: 1s - loss: 0.1817 - accuracy: 0.9375\n",
      " 20/251 [=>............................] - ETA: 1s - loss: 0.1786 - accuracy: 0.9349\n",
      " 26/251 [==>...........................] - ETA: 1s - loss: 0.1695 - accuracy: 0.9392\n",
      " 34/251 [===>..........................] - ETA: 1s - loss: 0.1648 - accuracy: 0.9411\n",
      " 44/251 [====>.........................] - ETA: 1s - loss: 0.1631 - accuracy: 0.9414\n",
      " 53/251 [=====>........................] - ETA: 1s - loss: 0.1725 - accuracy: 0.9374\n",
      " 63/251 [======>.......................] - ETA: 1s - loss: 0.1728 - accuracy: 0.9362\n",
      " 73/251 [=======>......................] - ETA: 1s - loss: 0.1744 - accuracy: 0.9355\n",
      " 83/251 [========>.....................] - ETA: 0s - loss: 0.1775 - accuracy: 0.9342\n",
      " 92/251 [=========>....................] - ETA: 0s - loss: 0.1774 - accuracy: 0.9337\n",
      "102/251 [===========>..................] - ETA: 0s - loss: 0.1806 - accuracy: 0.9339\n",
      "112/251 [============>.................] - ETA: 0s - loss: 0.1839 - accuracy: 0.9321\n",
      "119/251 [=============>................] - ETA: 0s - loss: 0.1812 - accuracy: 0.9335\n",
      "129/251 [==============>...............] - ETA: 0s - loss: 0.1815 - accuracy: 0.9334\n",
      "139/251 [===============>..............] - ETA: 0s - loss: 0.1848 - accuracy: 0.9316\n",
      "149/251 [================>.............] - ETA: 0s - loss: 0.1849 - accuracy: 0.9319\n",
      "160/251 [==================>...........] - ETA: 0s - loss: 0.1846 - accuracy: 0.9319\n",
      "171/251 [===================>..........] - ETA: 0s - loss: 0.1834 - accuracy: 0.9322\n",
      "181/251 [====================>.........] - ETA: 0s - loss: 0.1797 - accuracy: 0.9341\n",
      "190/251 [=====================>........] - ETA: 0s - loss: 0.1809 - accuracy: 0.9335\n",
      "199/251 [======================>.......] - ETA: 0s - loss: 0.1798 - accuracy: 0.9337\n",
      "208/251 [=======================>......] - ETA: 0s - loss: 0.1816 - accuracy: 0.9323\n",
      "215/251 [========================>.....] - ETA: 0s - loss: 0.1820 - accuracy: 0.9317\n",
      "223/251 [=========================>....] - ETA: 0s - loss: 0.1833 - accuracy: 0.9312\n",
      "232/251 [==========================>...] - ETA: 0s - loss: 0.1836 - accuracy: 0.9311\n",
      "241/251 [===========================>..] - ETA: 0s - loss: 0.1841 - accuracy: 0.9308\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.1826 - accuracy: 0.9315\n",
      "251/251 [==============================] - 2s 6ms/step - loss: 0.1826 - accuracy: 0.9315 - val_loss: 0.2004 - val_accuracy: 0.9117\n",
      "Epoch 10/10\n",
      "\n",
      "  1/251 [..............................] - ETA: 6s - loss: 0.2008 - accuracy: 0.9219\n",
      " 11/251 [>.............................] - ETA: 1s - loss: 0.1519 - accuracy: 0.9460\n",
      " 20/251 [=>............................] - ETA: 1s - loss: 0.1657 - accuracy: 0.9359\n",
      " 28/251 [==>...........................] - ETA: 1s - loss: 0.1761 - accuracy: 0.9297\n",
      " 37/251 [===>..........................] - ETA: 1s - loss: 0.1771 - accuracy: 0.9303\n",
      " 47/251 [====>.........................] - ETA: 1s - loss: 0.1788 - accuracy: 0.9299\n",
      " 56/251 [=====>........................] - ETA: 1s - loss: 0.1817 - accuracy: 0.9291\n",
      " 66/251 [======>.......................] - ETA: 1s - loss: 0.1801 - accuracy: 0.9304\n",
      " 76/251 [========>.....................] - ETA: 1s - loss: 0.1799 - accuracy: 0.9309\n",
      " 85/251 [=========>....................] - ETA: 0s - loss: 0.1762 - accuracy: 0.9312\n",
      " 95/251 [==========>...................] - ETA: 0s - loss: 0.1768 - accuracy: 0.9316\n",
      "105/251 [===========>..................] - ETA: 0s - loss: 0.1752 - accuracy: 0.9329\n",
      "115/251 [============>.................] - ETA: 0s - loss: 0.1769 - accuracy: 0.9325\n",
      "122/251 [=============>................] - ETA: 0s - loss: 0.1768 - accuracy: 0.9328\n",
      "132/251 [==============>...............] - ETA: 0s - loss: 0.1765 - accuracy: 0.9329\n",
      "141/251 [===============>..............] - ETA: 0s - loss: 0.1765 - accuracy: 0.9327\n",
      "147/251 [================>.............] - ETA: 0s - loss: 0.1768 - accuracy: 0.9326\n",
      "155/251 [=================>............] - ETA: 0s - loss: 0.1784 - accuracy: 0.9321\n",
      "160/251 [==================>...........] - ETA: 0s - loss: 0.1768 - accuracy: 0.9329\n",
      "164/251 [==================>...........] - ETA: 0s - loss: 0.1758 - accuracy: 0.9331\n",
      "171/251 [===================>..........] - ETA: 0s - loss: 0.1748 - accuracy: 0.9333\n",
      "179/251 [====================>.........] - ETA: 0s - loss: 0.1759 - accuracy: 0.9326\n",
      "186/251 [=====================>........] - ETA: 0s - loss: 0.1752 - accuracy: 0.9331\n",
      "195/251 [======================>.......] - ETA: 0s - loss: 0.1742 - accuracy: 0.9339\n",
      "204/251 [=======================>......] - ETA: 0s - loss: 0.1738 - accuracy: 0.9341\n",
      "213/251 [========================>.....] - ETA: 0s - loss: 0.1731 - accuracy: 0.9345\n",
      "223/251 [=========================>....] - ETA: 0s - loss: 0.1727 - accuracy: 0.9344\n",
      "233/251 [==========================>...] - ETA: 0s - loss: 0.1736 - accuracy: 0.9341\n",
      "242/251 [===========================>..] - ETA: 0s - loss: 0.1731 - accuracy: 0.9341\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 0.1721 - accuracy: 0.9349 - val_loss: 0.2744 - val_accuracy: 0.8776\n",
      "\n",
      "  1/501 [..............................] - ETA: 3:22\n",
      " 20/501 [>.............................] - ETA: 1s  \n",
      " 45/501 [=>............................] - ETA: 1s\n",
      " 75/501 [===>..........................] - ETA: 0s\n",
      "102/501 [=====>........................] - ETA: 0s\n",
      "130/501 [======>.......................] - ETA: 0s\n",
      "158/501 [========>.....................] - ETA: 0s\n",
      "189/501 [==========>...................] - ETA: 0s\n",
      "221/501 [============>.................] - ETA: 0s\n",
      "249/501 [=============>................] - ETA: 0s\n",
      "281/501 [===============>..............] - ETA: 0s\n",
      "302/501 [=================>............] - ETA: 0s\n",
      "330/501 [==================>...........] - ETA: 0s\n",
      "362/501 [====================>.........] - ETA: 0s\n",
      "393/501 [======================>.......] - ETA: 0s\n",
      "426/501 [========================>.....] - ETA: 0s\n",
      "457/501 [==========================>...] - ETA: 0s\n",
      "478/501 [===========================>..] - ETA: 0s\n",
      "501/501 [==============================] - 1s 2ms/step\n",
      "\n",
      " 1/66 [..............................] - ETA: 1s\n",
      "33/66 [==============>...............] - ETA: 0s\n",
      "65/66 [============================>.] - ETA: 0s\n",
      "66/66 [==============================] - 0s 2ms/step\n",
      "\n",
      "Sequential Classification Report (Train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.05      0.10      8006\n",
      "           1       0.51      1.00      0.68      8006\n",
      "\n",
      "    accuracy                           0.53     16012\n",
      "   macro avg       0.74      0.53      0.39     16012\n",
      "weighted avg       0.74      0.53      0.39     16012\n",
      "\n",
      "\n",
      "Sequential Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.05      0.10      1994\n",
      "           1       0.04      0.98      0.08        90\n",
      "\n",
      "    accuracy                           0.09      2084\n",
      "   macro avg       0.51      0.51      0.09      2084\n",
      "weighted avg       0.94      0.09      0.10      2084\n",
      "\n",
      "\n",
      "Sequential Confusion Matrix (Test):\n",
      "[[ 101 1893]\n",
      " [   2   88]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:/Users/twool/Downloads/intersection_analysis_2D.csv\") \n",
    "\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Convert TRUE/FALSE to 1/0\n",
    "df.replace({\"TRUE\": 1, \"FALSE\": 0, True: 1, False: 0}, inplace=True)\n",
    "\n",
    "# Undersample label 0, keep all label 1\n",
    "target_col = \"error\"\n",
    "label_0 = df[df[target_col] == 0]\n",
    "label_1 = df[df[target_col] == 1]\n",
    "label_0_sampled = label_0.sample(n=10000, random_state=42)\n",
    "df_balanced = pd.concat([label_0_sampled, label_1], ignore_index=True)\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split features and target\n",
    "ignore_cols = [\"geometry\"]\n",
    "features = df_balanced.drop(columns=ignore_cols + [target_col])\n",
    "target = df_balanced[target_col]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# SMOTE to balance training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\nTraining set after SMOTE:\")\n",
    "print(f\"Total data points: {len(y_train_res)}\")\n",
    "print(y_train_res.value_counts(normalize=True) * 100)\n",
    "\n",
    "print(\"\\nTest set (original):\")\n",
    "print(f\"Total data points: {len(y_test)}\")\n",
    "print(y_test.value_counts(normalize=True) * 100)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Use the same data loading process as requested\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train_res))\n",
    "train_dataset = train_dataset.batch(64).shuffle(buffer_size=1000)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_scaled, y_test))\n",
    "test_dataset = test_dataset.batch(64)\n",
    "\n",
    "# Initialize models\n",
    "models_dict = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(learning_rate=0.05, depth=7, iterations=500, random_state=42, verbose=0)\n",
    "}\n",
    "\n",
    "# Define Keras-based models\n",
    "def create_mlp_model(input_dim):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_dim=input_dim),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_cnn_model(input_dim):\n",
    "    model = models.Sequential([\n",
    "        layers.Reshape((input_dim, 1), input_shape=(input_dim,)),\n",
    "        layers.Conv1D(64, 3, activation='relu'),\n",
    "        layers.Conv1D(32, 3, activation='relu'),\n",
    "        layers.GlobalMaxPooling1D(),\n",
    "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_rnn_model(input_dim):\n",
    "    model = models.Sequential([\n",
    "        layers.Reshape((input_dim, 1), input_shape=(input_dim,)),\n",
    "        layers.LSTM(64, return_sequences=False),\n",
    "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_gru_model(input_dim):\n",
    "    model = models.Sequential([\n",
    "        layers.Reshape((input_dim, 1), input_shape=(input_dim,)),\n",
    "        layers.GRU(64, return_sequences=False),\n",
    "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_type=\"sklearn\"):\n",
    "    if model_type == \"sklearn\":\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "    elif model_type == \"keras\":\n",
    "        # Evaluate Keras models on train and test data\n",
    "        y_train_pred = (model.predict(X_train) > 0.5).astype(int)\n",
    "        y_test_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "    # Print classification reports\n",
    "    print(f\"\\n{model.__class__.__name__} Classification Report (Train):\")\n",
    "    print(classification_report(y_train, y_train_pred))\n",
    "    \n",
    "    print(f\"\\n{model.__class__.__name__} Classification Report (Test):\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    print(f\"\\n{model.__class__.__name__} Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models_dict.items():\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    evaluate_model(model, X_train_res, y_train_res, X_test, y_test, model_type=\"sklearn\")\n",
    "\n",
    "# Train and evaluate NN models\n",
    "def train_keras_model(model, train_dataset, test_dataset, epochs=10):\n",
    "    model.fit(train_dataset, epochs=epochs, validation_data=test_dataset)\n",
    "    evaluate_model(model, X_train_res, y_train_res, X_test, y_test, model_type=\"keras\")\n",
    "\n",
    "# Instantiate and train Keras NN models\n",
    "keras_models = [\n",
    "    create_mlp_model(X_train_res.shape[1]),\n",
    "    create_cnn_model(X_train_res.shape[1]),\n",
    "    create_rnn_model(X_train_res.shape[1]),\n",
    "    create_gru_model(X_train_res.shape[1])\n",
    "]\n",
    "\n",
    "for keras_model in keras_models:\n",
    "    print(f\"\\n{keras_model.__class__.__name__} Performance:\")\n",
    "    train_keras_model(keras_model, train_dataset, test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preview:\n",
      "                          geometry  num_of_lines  avg_angle_of_intersection  \\\n",
      "0    POINT (30.1132479 81.9040127)             3                   1.569418   \n",
      "1  POINT (30.11393889 81.90421187)             3                   0.000869   \n",
      "2  POINT (30.13443475 81.92446576)             3                   0.000869   \n",
      "3  POINT (30.12866542 81.91527886)             3                   0.001507   \n",
      "4  POINT (30.10870486 81.90333917)             4                   2.092366   \n",
      "\n",
      "   num_of_involved_line_intersections  \\\n",
      "0                                  20   \n",
      "1                                  16   \n",
      "2                                  16   \n",
      "3                                  20   \n",
      "4                                   7   \n",
      "\n",
      "   vicinity_of_involved_line_intersections  min_distance_to_endpoint  \\\n",
      "0                                 0.006751                 30.167739   \n",
      "1                                 0.005855                 30.168430   \n",
      "2                                 0.025495                 30.188933   \n",
      "3                                 0.031805                 30.183159   \n",
      "4                                 0.011274                 30.163172   \n",
      "\n",
      "   max_distance_to_endpoint  intersection_bounding_box_height  \\\n",
      "0                 30.216515                          2.280721   \n",
      "1                 30.177051                          0.740906   \n",
      "2                 30.198007                          0.740906   \n",
      "3                 30.202581                          1.954675   \n",
      "4                 30.163260                          0.028933   \n",
      "\n",
      "   intersection_bounding_box_width  error  intersecting_angles_variance  \\\n",
      "0                         0.002429      0                      1.137288   \n",
      "1                         0.000944      0                      1.106692   \n",
      "2                         0.000944      0                      1.106692   \n",
      "3                         0.002499      0                      1.111603   \n",
      "4                         0.000088      0                      0.196697   \n",
      "\n",
      "   vicinity_to_intersections  is_loop  shortest_perimeter  \n",
      "0                   0.013492     True            0.010618  \n",
      "1                   0.013665     True            0.010618  \n",
      "2                   0.034194     True            0.058085  \n",
      "3                   0.034205     True            0.038236  \n",
      "4                   0.027423     True            0.010618  \n",
      "\n",
      "Training set after SMOTE:\n",
      "error\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set:\n",
      "error\n",
      "0    95.96929\n",
      "1     4.03071\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Random Forest Performance:\n",
      "\n",
      "📊 RandomForestClassifier - Train Metrics\n",
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Percent Errors Identified: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      1.00      1.00      8000\n",
      "\n",
      "    accuracy                           1.00     16000\n",
      "   macro avg       1.00      1.00      1.00     16000\n",
      "weighted avg       1.00      1.00      1.00     16000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8000    0]\n",
      " [   0 8000]]\n",
      "\n",
      "📊 RandomForestClassifier - Test Metrics\n",
      "Accuracy: 0.9890\n",
      "F1 Score: 0.8655\n",
      "Percent Errors Identified: 88.10%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2000\n",
      "           1       0.85      0.88      0.87        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.92      0.94      0.93      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1987   13]\n",
      " [  10   74]]\n",
      "\n",
      "MLP Performance:\n",
      "\n",
      "📊 MLPClassifier - Train Metrics\n",
      "Accuracy: 0.9410\n",
      "F1 Score: 0.9416\n",
      "Percent Errors Identified: 95.08%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      8000\n",
      "           1       0.93      0.95      0.94      8000\n",
      "\n",
      "    accuracy                           0.94     16000\n",
      "   macro avg       0.94      0.94      0.94     16000\n",
      "weighted avg       0.94      0.94      0.94     16000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7450  550]\n",
      " [ 394 7606]]\n",
      "\n",
      "📊 MLPClassifier - Test Metrics\n",
      "Accuracy: 0.9343\n",
      "F1 Score: 0.5090\n",
      "Percent Errors Identified: 84.52%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      2000\n",
      "           1       0.36      0.85      0.51        84\n",
      "\n",
      "    accuracy                           0.93      2084\n",
      "   macro avg       0.68      0.89      0.74      2084\n",
      "weighted avg       0.97      0.93      0.95      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1876  124]\n",
      " [  13   71]]\n",
      "\n",
      "LightGBM Performance:\n",
      "[LightGBM] [Info] Number of positive: 8000, number of negative: 8000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2531\n",
      "[LightGBM] [Info] Number of data points in the train set: 16000, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "📊 LGBMClassifier - Train Metrics\n",
      "Accuracy: 0.9989\n",
      "F1 Score: 0.9989\n",
      "Percent Errors Identified: 99.99%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      1.00      1.00      8000\n",
      "\n",
      "    accuracy                           1.00     16000\n",
      "   macro avg       1.00      1.00      1.00     16000\n",
      "weighted avg       1.00      1.00      1.00     16000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7984   16]\n",
      " [   1 7999]]\n",
      "\n",
      "📊 LGBMClassifier - Test Metrics\n",
      "Accuracy: 0.9866\n",
      "F1 Score: 0.8427\n",
      "Percent Errors Identified: 89.29%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      2000\n",
      "           1       0.80      0.89      0.84        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.90      0.94      0.92      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1981   19]\n",
      " [   9   75]]\n",
      "\n",
      "XGBoost Performance:\n",
      "\n",
      "📊 XGBClassifier - Train Metrics\n",
      "Accuracy: 0.9996\n",
      "F1 Score: 0.9996\n",
      "Percent Errors Identified: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      1.00      1.00      8000\n",
      "\n",
      "    accuracy                           1.00     16000\n",
      "   macro avg       1.00      1.00      1.00     16000\n",
      "weighted avg       1.00      1.00      1.00     16000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7994    6]\n",
      " [   0 8000]]\n",
      "\n",
      "📊 XGBClassifier - Test Metrics\n",
      "Accuracy: 0.9866\n",
      "F1 Score: 0.8427\n",
      "Percent Errors Identified: 89.29%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      2000\n",
      "           1       0.80      0.89      0.84        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.90      0.94      0.92      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1981   19]\n",
      " [   9   75]]\n",
      "\n",
      "CatBoost Performance:\n",
      "\n",
      "📊 CatBoostClassifier - Train Metrics\n",
      "Accuracy: 0.9988\n",
      "F1 Score: 0.9988\n",
      "Percent Errors Identified: 99.99%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      1.00      1.00      8000\n",
      "\n",
      "    accuracy                           1.00     16000\n",
      "   macro avg       1.00      1.00      1.00     16000\n",
      "weighted avg       1.00      1.00      1.00     16000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7981   19]\n",
      " [   1 7999]]\n",
      "\n",
      "📊 CatBoostClassifier - Test Metrics\n",
      "Accuracy: 0.9856\n",
      "F1 Score: 0.8276\n",
      "Percent Errors Identified: 85.71%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2000\n",
      "           1       0.80      0.86      0.83        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.90      0.92      0.91      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1982   18]\n",
      " [  12   72]]\n",
      "\n",
      "MLP_Model Performance:\n",
      "\n",
      "  1/500 [..............................] - ETA: 22s\n",
      " 80/500 [===>..........................] - ETA: 0s \n",
      "172/500 [=========>....................] - ETA: 0s\n",
      "264/500 [==============>...............] - ETA: 0s\n",
      "360/500 [====================>.........] - ETA: 0s\n",
      "452/500 [==========================>...] - ETA: 0s\n",
      "500/500 [==============================] - 0s 554us/step\n",
      "\n",
      " 1/66 [..............................] - ETA: 2s\n",
      "66/66 [==============================] - 0s 597us/step\n",
      "\n",
      "📊 MLP_Model - Train Metrics\n",
      "Accuracy: 0.9494\n",
      "F1 Score: 0.9502\n",
      "Percent Errors Identified: 96.67%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      8000\n",
      "           1       0.93      0.97      0.95      8000\n",
      "\n",
      "    accuracy                           0.95     16000\n",
      "   macro avg       0.95      0.95      0.95     16000\n",
      "weighted avg       0.95      0.95      0.95     16000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7456  544]\n",
      " [ 266 7734]]\n",
      "\n",
      "📊 MLP_Model - Test Metrics\n",
      "Accuracy: 0.9280\n",
      "F1 Score: 0.4932\n",
      "Percent Errors Identified: 86.90%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      2000\n",
      "           1       0.34      0.87      0.49        84\n",
      "\n",
      "    accuracy                           0.93      2084\n",
      "   macro avg       0.67      0.90      0.73      2084\n",
      "weighted avg       0.97      0.93      0.94      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1861  139]\n",
      " [  11   73]]\n",
      "\n",
      "CNN_Model Performance:\n",
      "\n",
      "  1/500 [..............................] - ETA: 33s\n",
      " 71/500 [===>..........................] - ETA: 0s \n",
      "148/500 [=======>......................] - ETA: 0s\n",
      "220/500 [============>.................] - ETA: 0s\n",
      "296/500 [================>.............] - ETA: 0s\n",
      "370/500 [=====================>........] - ETA: 0s\n",
      "443/500 [=========================>....] - ETA: 0s\n",
      "480/500 [===========================>..] - ETA: 0s\n",
      "500/500 [==============================] - 0s 736us/step\n",
      "\n",
      " 1/66 [..............................] - ETA: 4s\n",
      "66/66 [==============================] - 0s 741us/step\n",
      "\n",
      "📊 CNN_Model - Train Metrics\n",
      "Accuracy: 0.8950\n",
      "F1 Score: 0.8990\n",
      "Percent Errors Identified: 93.47%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89      8000\n",
      "           1       0.87      0.93      0.90      8000\n",
      "\n",
      "    accuracy                           0.90     16000\n",
      "   macro avg       0.90      0.90      0.89     16000\n",
      "weighted avg       0.90      0.90      0.89     16000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6842 1158]\n",
      " [ 522 7478]]\n",
      "\n",
      "📊 CNN_Model - Test Metrics\n",
      "Accuracy: 0.8652\n",
      "F1 Score: 0.3540\n",
      "Percent Errors Identified: 91.67%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92      2000\n",
      "           1       0.22      0.92      0.35        84\n",
      "\n",
      "    accuracy                           0.87      2084\n",
      "   macro avg       0.61      0.89      0.64      2084\n",
      "weighted avg       0.96      0.87      0.90      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1726  274]\n",
      " [   7   77]]\n",
      "\n",
      "RNN_Model Performance:\n",
      "\n",
      "  1/500 [..............................] - ETA: 3:15\n",
      " 18/500 [>.............................] - ETA: 1s  \n",
      " 48/500 [=>............................] - ETA: 0s\n",
      " 78/500 [===>..........................] - ETA: 0s\n",
      "107/500 [=====>........................] - ETA: 0s\n",
      "137/500 [=======>......................] - ETA: 0s\n",
      "167/500 [=========>....................] - ETA: 0s\n",
      "196/500 [==========>...................] - ETA: 0s\n",
      "226/500 [============>.................] - ETA: 0s\n",
      "254/500 [==============>...............] - ETA: 0s\n",
      "284/500 [================>.............] - ETA: 0s\n",
      "314/500 [=================>............] - ETA: 0s\n",
      "344/500 [===================>..........] - ETA: 0s\n",
      "374/500 [=====================>........] - ETA: 0s\n",
      "402/500 [=======================>......] - ETA: 0s\n",
      "431/500 [========================>.....] - ETA: 0s\n",
      "460/500 [==========================>...] - ETA: 0s\n",
      "490/500 [============================>.] - ETA: 0s\n",
      "500/500 [==============================] - 1s 2ms/step\n",
      "\n",
      " 1/66 [..............................] - ETA: 25s\n",
      "28/66 [===========>..................] - ETA: 0s \n",
      "45/66 [===================>..........] - ETA: 0s\n",
      "66/66 [==============================] - 1s 2ms/step\n",
      "\n",
      "📊 RNN_Model - Train Metrics\n",
      "Accuracy: 0.9326\n",
      "F1 Score: 0.9335\n",
      "Percent Errors Identified: 94.69%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      8000\n",
      "           1       0.92      0.95      0.93      8000\n",
      "\n",
      "    accuracy                           0.93     16000\n",
      "   macro avg       0.93      0.93      0.93     16000\n",
      "weighted avg       0.93      0.93      0.93     16000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7346  654]\n",
      " [ 425 7575]]\n",
      "\n",
      "📊 RNN_Model - Test Metrics\n",
      "Accuracy: 0.9141\n",
      "F1 Score: 0.4458\n",
      "Percent Errors Identified: 85.71%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      2000\n",
      "           1       0.30      0.86      0.45        84\n",
      "\n",
      "    accuracy                           0.91      2084\n",
      "   macro avg       0.65      0.89      0.70      2084\n",
      "weighted avg       0.97      0.91      0.93      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1833  167]\n",
      " [  12   72]]\n",
      "\n",
      "GRU_Model Performance:\n",
      "\n",
      "  1/500 [..............................] - ETA: 3:02\n",
      " 38/500 [=>............................] - ETA: 0s  \n",
      " 74/500 [===>..........................] - ETA: 0s\n",
      "109/500 [=====>........................] - ETA: 0s\n",
      "145/500 [=======>......................] - ETA: 0s\n",
      "182/500 [=========>....................] - ETA: 0s\n",
      "216/500 [===========>..................] - ETA: 0s\n",
      "251/500 [==============>...............] - ETA: 0s\n",
      "285/500 [================>.............] - ETA: 0s\n",
      "320/500 [==================>...........] - ETA: 0s\n",
      "354/500 [====================>.........] - ETA: 0s\n",
      "390/500 [======================>.......] - ETA: 0s\n",
      "428/500 [========================>.....] - ETA: 0s\n",
      "460/500 [==========================>...] - ETA: 0s\n",
      "491/500 [============================>.] - ETA: 0s\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "\n",
      " 1/66 [..............................] - ETA: 23s\n",
      "35/66 [==============>...............] - ETA: 0s \n",
      "66/66 [==============================] - 0s 1ms/step\n",
      "\n",
      "📊 GRU_Model - Train Metrics\n",
      "Accuracy: 0.9280\n",
      "F1 Score: 0.9293\n",
      "Percent Errors Identified: 94.67%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93      8000\n",
      "           1       0.91      0.95      0.93      8000\n",
      "\n",
      "    accuracy                           0.93     16000\n",
      "   macro avg       0.93      0.93      0.93     16000\n",
      "weighted avg       0.93      0.93      0.93     16000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7274  726]\n",
      " [ 426 7574]]\n",
      "\n",
      "📊 GRU_Model - Test Metrics\n",
      "Accuracy: 0.8992\n",
      "F1 Score: 0.4101\n",
      "Percent Errors Identified: 86.90%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      2000\n",
      "           1       0.27      0.87      0.41        84\n",
      "\n",
      "    accuracy                           0.90      2084\n",
      "   macro avg       0.63      0.88      0.68      2084\n",
      "weighted avg       0.96      0.90      0.92      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1801  199]\n",
      " [  11   73]]\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Imports\n",
    "# ========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# ========================\n",
    "# Load and Prepare Dataset\n",
    "# ========================\n",
    "df = pd.read_csv(r\"C:/Users/twool/Downloads/intersection_analysis_2D.csv\") \n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())\n",
    "\n",
    "df.replace({\"TRUE\": 1, \"FALSE\": 0, True: 1, False: 0}, inplace=True)\n",
    "\n",
    "# Balance dataset by undersampling class 0\n",
    "target_col = \"error\"\n",
    "label_0 = df[df[target_col] == 0].sample(n=10000, random_state=42)\n",
    "label_1 = df[df[target_col] == 1]\n",
    "df_balanced = pd.concat([label_0, label_1]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# ========================\n",
    "# Feature/Target Split\n",
    "# ========================\n",
    "ignore_cols = [\"geometry\"]\n",
    "features = df_balanced.drop(columns=ignore_cols + [target_col])\n",
    "target = df_balanced[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, stratify=target)\n",
    "\n",
    "# ========================\n",
    "# Apply SMOTE\n",
    "# ========================\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\nTraining set after SMOTE:\")\n",
    "print(y_train_res.value_counts(normalize=True) * 100)\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "print(y_test.value_counts(normalize=True) * 100)\n",
    "\n",
    "# ========================\n",
    "# Standardize Features\n",
    "# ========================\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train_res)).batch(64).shuffle(1000)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_scaled, y_test)).batch(64)\n",
    "\n",
    "# ========================\n",
    "# Scikit-learn Models\n",
    "# ========================\n",
    "models_dict = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'CatBoost': CatBoostClassifier(learning_rate=0.05, depth=7, iterations=500, random_state=42, verbose=0)\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# TensorFlow Models\n",
    "# ========================\n",
    "def create_mlp_model(input_dim):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_dim=input_dim),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model._name = \"MLP_Model\"\n",
    "    return model\n",
    "\n",
    "def create_cnn_model(input_dim):\n",
    "    model = models.Sequential([\n",
    "        layers.Reshape((input_dim, 1), input_shape=(input_dim,)),\n",
    "        layers.Conv1D(64, 3, activation='relu'),\n",
    "        layers.Conv1D(32, 3, activation='relu'),\n",
    "        layers.GlobalMaxPooling1D(),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model._name = \"CNN_Model\"\n",
    "    return model\n",
    "\n",
    "def create_rnn_model(input_dim):\n",
    "    model = models.Sequential([\n",
    "        layers.Reshape((input_dim, 1), input_shape=(input_dim,)),\n",
    "        layers.LSTM(64),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model._name = \"RNN_Model\"\n",
    "    return model\n",
    "\n",
    "def create_gru_model(input_dim):\n",
    "    model = models.Sequential([\n",
    "        layers.Reshape((input_dim, 1), input_shape=(input_dim,)),\n",
    "        layers.GRU(64),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model._name = \"GRU_Model\"\n",
    "    return model\n",
    "\n",
    "\n",
    "# ========================\n",
    "# Evaluation Function\n",
    "# ========================\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_type=\"sklearn\", name=None):\n",
    "    if model_type == \"sklearn\":\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        model_name = name or model.__class__.__name__\n",
    "    else:  # keras\n",
    "        y_train_pred = (model.predict(X_train) > 0.5).astype(int).flatten()\n",
    "        y_test_pred = (model.predict(X_test) > 0.5).astype(int).flatten()\n",
    "        model_name = name or model.name\n",
    "\n",
    "    def print_metrics(y_true, y_pred, dataset_name):\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        tp = cm[1, 1]\n",
    "        fn = cm[1, 0]\n",
    "        percent_errors_identified = (tp / (tp + fn)) * 100 if (tp + fn) > 0 else 0\n",
    "\n",
    "        print(f\"\\n📊 {model_name} - {dataset_name} Metrics\")\n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"Percent Errors Identified: {percent_errors_identified:.2f}%\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    print_metrics(y_train, y_train_pred, \"Train\")\n",
    "    print_metrics(y_test, y_test_pred, \"Test\")\n",
    "    \n",
    "# ========================\n",
    "# Train & Evaluate Scikit-learn Models\n",
    "# ========================\n",
    "for name, model in models_dict.items():\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    evaluate_model(model, X_train_res, y_train_res, X_test, y_test)\n",
    "\n",
    "# ========================\n",
    "# Train & Evaluate TensorFlow Models\n",
    "# ========================\n",
    "def train_keras_model(model, train_dataset, test_dataset, input_data):\n",
    "    model.fit(train_dataset, epochs=10, validation_data=test_dataset, verbose=0)\n",
    "    evaluate_model(model, input_data['X_train'], input_data['y_train'], input_data['X_test'], input_data['y_test'], model_type=\"keras\")\n",
    "\n",
    "keras_models = [\n",
    "    create_mlp_model(X_train_res.shape[1]),\n",
    "    create_cnn_model(X_train_res.shape[1]),\n",
    "    create_rnn_model(X_train_res.shape[1]),\n",
    "    create_gru_model(X_train_res.shape[1])\n",
    "]\n",
    "\n",
    "keras_input_data = {\n",
    "    'X_train': X_train_scaled,\n",
    "    'y_train': y_train_res,\n",
    "    'X_test': X_test_scaled,\n",
    "    'y_test': y_test\n",
    "}\n",
    "\n",
    "for model in keras_models:\n",
    "    print(f\"\\n{model.name} Performance:\")\n",
    "    train_keras_model(model, train_dataset, test_dataset, keras_input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying augmentation method: smote\n",
      "\n",
      "Random Forest Performance with smote:\n",
      "\n",
      "📊 RandomForestClassifier - Train Metrics\n",
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Percent Errors Identified: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      1.00      1.00      8000\n",
      "\n",
      "    accuracy                           1.00     16000\n",
      "   macro avg       1.00      1.00      1.00     16000\n",
      "weighted avg       1.00      1.00      1.00     16000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8000    0]\n",
      " [   0 8000]]\n",
      "\n",
      "📊 RandomForestClassifier - Test Metrics\n",
      "Accuracy: 0.9885\n",
      "F1 Score: 0.8605\n",
      "Percent Errors Identified: 88.10%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2000\n",
      "           1       0.84      0.88      0.86        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.92      0.94      0.93      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1986   14]\n",
      " [  10   74]]\n",
      "\n",
      "MLP Performance with smote:\n",
      "\n",
      "📊 MLPClassifier - Train Metrics\n",
      "Accuracy: 0.9858\n",
      "F1 Score: 0.9859\n",
      "Percent Errors Identified: 99.10%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      8000\n",
      "           1       0.98      0.99      0.99      8000\n",
      "\n",
      "    accuracy                           0.99     16000\n",
      "   macro avg       0.99      0.99      0.99     16000\n",
      "weighted avg       0.99      0.99      0.99     16000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7845  155]\n",
      " [  72 7928]]\n",
      "\n",
      "📊 MLPClassifier - Test Metrics\n",
      "Accuracy: 0.9664\n",
      "F1 Score: 0.6535\n",
      "Percent Errors Identified: 78.57%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      2000\n",
      "           1       0.56      0.79      0.65        84\n",
      "\n",
      "    accuracy                           0.97      2084\n",
      "   macro avg       0.78      0.88      0.82      2084\n",
      "weighted avg       0.97      0.97      0.97      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1948   52]\n",
      " [  18   66]]\n",
      "\n",
      "LightGBM Performance with smote:\n",
      "[LightGBM] [Info] Number of positive: 8000, number of negative: 8000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2539\n",
      "[LightGBM] [Info] Number of data points in the train set: 16000, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "📊 LGBMClassifier - Train Metrics\n",
      "Accuracy: 0.9990\n",
      "F1 Score: 0.9990\n",
      "Percent Errors Identified: 99.99%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      1.00      1.00      8000\n",
      "\n",
      "    accuracy                           1.00     16000\n",
      "   macro avg       1.00      1.00      1.00     16000\n",
      "weighted avg       1.00      1.00      1.00     16000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7985   15]\n",
      " [   1 7999]]\n",
      "\n",
      "📊 LGBMClassifier - Test Metrics\n",
      "Accuracy: 0.9890\n",
      "F1 Score: 0.8701\n",
      "Percent Errors Identified: 91.67%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      2000\n",
      "           1       0.83      0.92      0.87        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.91      0.95      0.93      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1984   16]\n",
      " [   7   77]]\n",
      "\n",
      "XGBoost Performance with smote:\n",
      "\n",
      "📊 XGBClassifier - Train Metrics\n",
      "Accuracy: 0.9996\n",
      "F1 Score: 0.9996\n",
      "Percent Errors Identified: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      1.00      1.00      8000\n",
      "\n",
      "    accuracy                           1.00     16000\n",
      "   macro avg       1.00      1.00      1.00     16000\n",
      "weighted avg       1.00      1.00      1.00     16000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7994    6]\n",
      " [   0 8000]]\n",
      "\n",
      "📊 XGBClassifier - Test Metrics\n",
      "Accuracy: 0.9870\n",
      "F1 Score: 0.8508\n",
      "Percent Errors Identified: 91.67%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      2000\n",
      "           1       0.79      0.92      0.85        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.90      0.95      0.92      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1980   20]\n",
      " [   7   77]]\n",
      "\n",
      "CatBoost Performance with smote:\n",
      "\n",
      "📊 CatBoostClassifier - Train Metrics\n",
      "Accuracy: 0.9983\n",
      "F1 Score: 0.9983\n",
      "Percent Errors Identified: 99.98%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      1.00      1.00      8000\n",
      "\n",
      "    accuracy                           1.00     16000\n",
      "   macro avg       1.00      1.00      1.00     16000\n",
      "weighted avg       1.00      1.00      1.00     16000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7975   25]\n",
      " [   2 7998]]\n",
      "\n",
      "📊 CatBoostClassifier - Test Metrics\n",
      "Accuracy: 0.9861\n",
      "F1 Score: 0.8380\n",
      "Percent Errors Identified: 89.29%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      2000\n",
      "           1       0.79      0.89      0.84        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.89      0.94      0.92      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1980   20]\n",
      " [   9   75]]\n",
      "\n",
      "Trying augmentation method: adasyn\n",
      "\n",
      "Random Forest Performance with adasyn:\n",
      "\n",
      "📊 RandomForestClassifier - Train Metrics\n",
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Percent Errors Identified: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      1.00      1.00      7977\n",
      "\n",
      "    accuracy                           1.00     15977\n",
      "   macro avg       1.00      1.00      1.00     15977\n",
      "weighted avg       1.00      1.00      1.00     15977\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8000    0]\n",
      " [   0 7977]]\n",
      "\n",
      "📊 RandomForestClassifier - Test Metrics\n",
      "Accuracy: 0.9861\n",
      "F1 Score: 0.8304\n",
      "Percent Errors Identified: 84.52%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2000\n",
      "           1       0.82      0.85      0.83        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.90      0.92      0.91      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1984   16]\n",
      " [  13   71]]\n",
      "\n",
      "MLP Performance with adasyn:\n",
      "\n",
      "📊 MLPClassifier - Train Metrics\n",
      "Accuracy: 0.9847\n",
      "F1 Score: 0.9848\n",
      "Percent Errors Identified: 99.36%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      8000\n",
      "           1       0.98      0.99      0.98      7977\n",
      "\n",
      "    accuracy                           0.98     15977\n",
      "   macro avg       0.98      0.98      0.98     15977\n",
      "weighted avg       0.98      0.98      0.98     15977\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7806  194]\n",
      " [  51 7926]]\n",
      "\n",
      "📊 MLPClassifier - Test Metrics\n",
      "Accuracy: 0.9631\n",
      "F1 Score: 0.6351\n",
      "Percent Errors Identified: 79.76%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      2000\n",
      "           1       0.53      0.80      0.64        84\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.76      0.88      0.81      2084\n",
      "weighted avg       0.97      0.96      0.97      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1940   60]\n",
      " [  17   67]]\n",
      "\n",
      "LightGBM Performance with adasyn:\n",
      "[LightGBM] [Info] Number of positive: 7977, number of negative: 8000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2546\n",
      "[LightGBM] [Info] Number of data points in the train set: 15977, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499280 -> initscore=-0.002879\n",
      "[LightGBM] [Info] Start training from score -0.002879\n",
      "\n",
      "📊 LGBMClassifier - Train Metrics\n",
      "Accuracy: 0.9983\n",
      "F1 Score: 0.9983\n",
      "Percent Errors Identified: 99.97%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      1.00      1.00      7977\n",
      "\n",
      "    accuracy                           1.00     15977\n",
      "   macro avg       1.00      1.00      1.00     15977\n",
      "weighted avg       1.00      1.00      1.00     15977\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7975   25]\n",
      " [   2 7975]]\n",
      "\n",
      "📊 LGBMClassifier - Test Metrics\n",
      "Accuracy: 0.9851\n",
      "F1 Score: 0.8324\n",
      "Percent Errors Identified: 91.67%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      2000\n",
      "           1       0.76      0.92      0.83        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.88      0.95      0.91      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1976   24]\n",
      " [   7   77]]\n",
      "\n",
      "XGBoost Performance with adasyn:\n",
      "\n",
      "📊 XGBClassifier - Train Metrics\n",
      "Accuracy: 0.9996\n",
      "F1 Score: 0.9996\n",
      "Percent Errors Identified: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      1.00      1.00      7977\n",
      "\n",
      "    accuracy                           1.00     15977\n",
      "   macro avg       1.00      1.00      1.00     15977\n",
      "weighted avg       1.00      1.00      1.00     15977\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7994    6]\n",
      " [   0 7977]]\n",
      "\n",
      "📊 XGBClassifier - Test Metrics\n",
      "Accuracy: 0.9856\n",
      "F1 Score: 0.8370\n",
      "Percent Errors Identified: 91.67%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      2000\n",
      "           1       0.77      0.92      0.84        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.88      0.95      0.91      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1977   23]\n",
      " [   7   77]]\n",
      "\n",
      "CatBoost Performance with adasyn:\n",
      "\n",
      "📊 CatBoostClassifier - Train Metrics\n",
      "Accuracy: 0.9984\n",
      "F1 Score: 0.9984\n",
      "Percent Errors Identified: 99.99%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      1.00      1.00      7977\n",
      "\n",
      "    accuracy                           1.00     15977\n",
      "   macro avg       1.00      1.00      1.00     15977\n",
      "weighted avg       1.00      1.00      1.00     15977\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7975   25]\n",
      " [   1 7976]]\n",
      "\n",
      "📊 CatBoostClassifier - Test Metrics\n",
      "Accuracy: 0.9851\n",
      "F1 Score: 0.8324\n",
      "Percent Errors Identified: 91.67%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      2000\n",
      "           1       0.76      0.92      0.83        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.88      0.95      0.91      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1976   24]\n",
      " [   7   77]]\n",
      "\n",
      "Trying augmentation method: random_undersampling\n",
      "\n",
      "Random Forest Performance with random_undersampling:\n",
      "\n",
      "📊 RandomForestClassifier - Train Metrics\n",
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Percent Errors Identified: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       321\n",
      "           1       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00       334\n",
      "   macro avg       1.00      1.00      1.00       334\n",
      "weighted avg       1.00      1.00      1.00       334\n",
      "\n",
      "Confusion Matrix:\n",
      "[[321   0]\n",
      " [  0  13]]\n",
      "\n",
      "📊 RandomForestClassifier - Test Metrics\n",
      "Accuracy: 0.9626\n",
      "F1 Score: 0.4348\n",
      "Percent Errors Identified: 35.71%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      2000\n",
      "           1       0.56      0.36      0.43        84\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.76      0.67      0.71      2084\n",
      "weighted avg       0.96      0.96      0.96      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1976   24]\n",
      " [  54   30]]\n",
      "\n",
      "MLP Performance with random_undersampling:\n",
      "\n",
      "📊 MLPClassifier - Train Metrics\n",
      "Accuracy: 0.9850\n",
      "F1 Score: 0.7826\n",
      "Percent Errors Identified: 69.23%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       321\n",
      "           1       0.90      0.69      0.78        13\n",
      "\n",
      "    accuracy                           0.99       334\n",
      "   macro avg       0.94      0.84      0.89       334\n",
      "weighted avg       0.98      0.99      0.98       334\n",
      "\n",
      "Confusion Matrix:\n",
      "[[320   1]\n",
      " [  4   9]]\n",
      "\n",
      "📊 MLPClassifier - Test Metrics\n",
      "Accuracy: 0.9554\n",
      "F1 Score: 0.3673\n",
      "Percent Errors Identified: 32.14%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      2000\n",
      "           1       0.43      0.32      0.37        84\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.70      0.65      0.67      2084\n",
      "weighted avg       0.95      0.96      0.95      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1964   36]\n",
      " [  57   27]]\n",
      "\n",
      "LightGBM Performance with random_undersampling:\n",
      "[LightGBM] [Info] Number of positive: 13, number of negative: 321\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 889\n",
      "[LightGBM] [Info] Number of data points in the train set: 334, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038922 -> initscore=-3.206492\n",
      "[LightGBM] [Info] Start training from score -3.206492\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "📊 LGBMClassifier - Train Metrics\n",
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Percent Errors Identified: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       321\n",
      "           1       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00       334\n",
      "   macro avg       1.00      1.00      1.00       334\n",
      "weighted avg       1.00      1.00      1.00       334\n",
      "\n",
      "Confusion Matrix:\n",
      "[[321   0]\n",
      " [  0  13]]\n",
      "\n",
      "📊 LGBMClassifier - Test Metrics\n",
      "Accuracy: 0.9515\n",
      "F1 Score: 0.3311\n",
      "Percent Errors Identified: 29.76%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      2000\n",
      "           1       0.37      0.30      0.33        84\n",
      "\n",
      "    accuracy                           0.95      2084\n",
      "   macro avg       0.67      0.64      0.65      2084\n",
      "weighted avg       0.95      0.95      0.95      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1958   42]\n",
      " [  59   25]]\n",
      "\n",
      "XGBoost Performance with random_undersampling:\n",
      "\n",
      "📊 XGBClassifier - Train Metrics\n",
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Percent Errors Identified: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       321\n",
      "           1       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00       334\n",
      "   macro avg       1.00      1.00      1.00       334\n",
      "weighted avg       1.00      1.00      1.00       334\n",
      "\n",
      "Confusion Matrix:\n",
      "[[321   0]\n",
      " [  0  13]]\n",
      "\n",
      "📊 XGBClassifier - Test Metrics\n",
      "Accuracy: 0.9573\n",
      "F1 Score: 0.3946\n",
      "Percent Errors Identified: 34.52%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      2000\n",
      "           1       0.46      0.35      0.39        84\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.72      0.66      0.69      2084\n",
      "weighted avg       0.95      0.96      0.95      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1966   34]\n",
      " [  55   29]]\n",
      "\n",
      "CatBoost Performance with random_undersampling:\n",
      "\n",
      "📊 CatBoostClassifier - Train Metrics\n",
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Percent Errors Identified: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       321\n",
      "           1       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00       334\n",
      "   macro avg       1.00      1.00      1.00       334\n",
      "weighted avg       1.00      1.00      1.00       334\n",
      "\n",
      "Confusion Matrix:\n",
      "[[321   0]\n",
      " [  0  13]]\n",
      "\n",
      "📊 CatBoostClassifier - Test Metrics\n",
      "Accuracy: 0.9587\n",
      "F1 Score: 0.4110\n",
      "Percent Errors Identified: 35.71%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      2000\n",
      "           1       0.48      0.36      0.41        84\n",
      "\n",
      "    accuracy                           0.96      2084\n",
      "   macro avg       0.73      0.67      0.69      2084\n",
      "weighted avg       0.95      0.96      0.96      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1968   32]\n",
      " [  54   30]]\n",
      "\n",
      "Trying augmentation method: random_oversampling\n",
      "\n",
      "Random Forest Performance with random_oversampling:\n",
      "\n",
      "📊 RandomForestClassifier - Train Metrics\n",
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Percent Errors Identified: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7671\n",
      "           1       1.00      1.00      1.00       329\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       1.00      1.00      1.00      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7671    0]\n",
      " [   0  329]]\n",
      "\n",
      "📊 RandomForestClassifier - Test Metrics\n",
      "Accuracy: 0.9837\n",
      "F1 Score: 0.7671\n",
      "Percent Errors Identified: 66.67%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2000\n",
      "           1       0.90      0.67      0.77        84\n",
      "\n",
      "    accuracy                           0.98      2084\n",
      "   macro avg       0.94      0.83      0.88      2084\n",
      "weighted avg       0.98      0.98      0.98      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1994    6]\n",
      " [  28   56]]\n",
      "\n",
      "MLP Performance with random_oversampling:\n",
      "\n",
      "📊 MLPClassifier - Train Metrics\n",
      "Accuracy: 0.9900\n",
      "F1 Score: 0.8718\n",
      "Percent Errors Identified: 82.67%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7671\n",
      "           1       0.92      0.83      0.87       329\n",
      "\n",
      "    accuracy                           0.99      8000\n",
      "   macro avg       0.96      0.91      0.93      8000\n",
      "weighted avg       0.99      0.99      0.99      8000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7648   23]\n",
      " [  57  272]]\n",
      "\n",
      "📊 MLPClassifier - Test Metrics\n",
      "Accuracy: 0.9736\n",
      "F1 Score: 0.6452\n",
      "Percent Errors Identified: 59.52%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      2000\n",
      "           1       0.70      0.60      0.65        84\n",
      "\n",
      "    accuracy                           0.97      2084\n",
      "   macro avg       0.84      0.79      0.82      2084\n",
      "weighted avg       0.97      0.97      0.97      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1979   21]\n",
      " [  34   50]]\n",
      "\n",
      "LightGBM Performance with random_oversampling:\n",
      "[LightGBM] [Info] Number of positive: 329, number of negative: 7671\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2323\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.041125 -> initscore=-3.149145\n",
      "[LightGBM] [Info] Start training from score -3.149145\n",
      "\n",
      "📊 LGBMClassifier - Train Metrics\n",
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Percent Errors Identified: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7671\n",
      "           1       1.00      1.00      1.00       329\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       1.00      1.00      1.00      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7671    0]\n",
      " [   0  329]]\n",
      "\n",
      "📊 LGBMClassifier - Test Metrics\n",
      "Accuracy: 0.9890\n",
      "F1 Score: 0.8516\n",
      "Percent Errors Identified: 78.57%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2000\n",
      "           1       0.93      0.79      0.85        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.96      0.89      0.92      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1995    5]\n",
      " [  18   66]]\n",
      "\n",
      "XGBoost Performance with random_oversampling:\n",
      "\n",
      "📊 XGBClassifier - Train Metrics\n",
      "Accuracy: 0.9999\n",
      "F1 Score: 0.9985\n",
      "Percent Errors Identified: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7671\n",
      "           1       1.00      1.00      1.00       329\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       1.00      1.00      1.00      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7670    1]\n",
      " [   0  329]]\n",
      "\n",
      "📊 XGBClassifier - Test Metrics\n",
      "Accuracy: 0.9885\n",
      "F1 Score: 0.8442\n",
      "Percent Errors Identified: 77.38%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2000\n",
      "           1       0.93      0.77      0.84        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.96      0.89      0.92      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1995    5]\n",
      " [  19   65]]\n",
      "\n",
      "CatBoost Performance with random_oversampling:\n",
      "\n",
      "📊 CatBoostClassifier - Train Metrics\n",
      "Accuracy: 0.9998\n",
      "F1 Score: 0.9970\n",
      "Percent Errors Identified: 99.39%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7671\n",
      "           1       1.00      0.99      1.00       329\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       1.00      1.00      1.00      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7671    0]\n",
      " [   2  327]]\n",
      "\n",
      "📊 CatBoostClassifier - Test Metrics\n",
      "Accuracy: 0.9861\n",
      "F1 Score: 0.8105\n",
      "Percent Errors Identified: 73.81%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2000\n",
      "           1       0.90      0.74      0.81        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.94      0.87      0.90      2084\n",
      "weighted avg       0.99      0.99      0.99      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1993    7]\n",
      " [  22   62]]\n",
      "\n",
      "Trying augmentation method: gaussian_noise\n",
      "\n",
      "Random Forest Performance with gaussian_noise:\n",
      "\n",
      "📊 RandomForestClassifier - Train Metrics\n",
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Percent Errors Identified: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      1.00      1.00       334\n",
      "\n",
      "    accuracy                           1.00      8334\n",
      "   macro avg       1.00      1.00      1.00      8334\n",
      "weighted avg       1.00      1.00      1.00      8334\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8000    0]\n",
      " [   0  334]]\n",
      "\n",
      "📊 RandomForestClassifier - Test Metrics\n",
      "Accuracy: 0.9827\n",
      "F1 Score: 0.7500\n",
      "Percent Errors Identified: 64.29%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2000\n",
      "           1       0.90      0.64      0.75        84\n",
      "\n",
      "    accuracy                           0.98      2084\n",
      "   macro avg       0.94      0.82      0.87      2084\n",
      "weighted avg       0.98      0.98      0.98      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1994    6]\n",
      " [  30   54]]\n",
      "\n",
      "MLP Performance with gaussian_noise:\n",
      "\n",
      "📊 MLPClassifier - Train Metrics\n",
      "Accuracy: 0.9888\n",
      "F1 Score: 0.8442\n",
      "Percent Errors Identified: 75.45%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      8000\n",
      "           1       0.96      0.75      0.84       334\n",
      "\n",
      "    accuracy                           0.99      8334\n",
      "   macro avg       0.97      0.88      0.92      8334\n",
      "weighted avg       0.99      0.99      0.99      8334\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7989   11]\n",
      " [  82  252]]\n",
      "\n",
      "📊 MLPClassifier - Test Metrics\n",
      "Accuracy: 0.9750\n",
      "F1 Score: 0.6232\n",
      "Percent Errors Identified: 51.19%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      2000\n",
      "           1       0.80      0.51      0.62        84\n",
      "\n",
      "    accuracy                           0.98      2084\n",
      "   macro avg       0.89      0.75      0.81      2084\n",
      "weighted avg       0.97      0.98      0.97      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1989   11]\n",
      " [  41   43]]\n",
      "\n",
      "LightGBM Performance with gaussian_noise:\n",
      "[LightGBM] [Info] Number of positive: 334, number of negative: 8000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 8334, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.040077 -> initscore=-3.176056\n",
      "[LightGBM] [Info] Start training from score -3.176056\n",
      "\n",
      "📊 LGBMClassifier - Train Metrics\n",
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Percent Errors Identified: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      1.00      1.00       334\n",
      "\n",
      "    accuracy                           1.00      8334\n",
      "   macro avg       1.00      1.00      1.00      8334\n",
      "weighted avg       1.00      1.00      1.00      8334\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8000    0]\n",
      " [   0  334]]\n",
      "\n",
      "📊 LGBMClassifier - Test Metrics\n",
      "Accuracy: 0.9851\n",
      "F1 Score: 0.7891\n",
      "Percent Errors Identified: 69.05%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2000\n",
      "           1       0.92      0.69      0.79        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.95      0.84      0.89      2084\n",
      "weighted avg       0.98      0.99      0.98      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1995    5]\n",
      " [  26   58]]\n",
      "\n",
      "XGBoost Performance with gaussian_noise:\n",
      "\n",
      "📊 XGBClassifier - Train Metrics\n",
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n",
      "Percent Errors Identified: 100.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      1.00      1.00       334\n",
      "\n",
      "    accuracy                           1.00      8334\n",
      "   macro avg       1.00      1.00      1.00      8334\n",
      "weighted avg       1.00      1.00      1.00      8334\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8000    0]\n",
      " [   0  334]]\n",
      "\n",
      "📊 XGBClassifier - Test Metrics\n",
      "Accuracy: 0.9837\n",
      "F1 Score: 0.7671\n",
      "Percent Errors Identified: 66.67%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2000\n",
      "           1       0.90      0.67      0.77        84\n",
      "\n",
      "    accuracy                           0.98      2084\n",
      "   macro avg       0.94      0.83      0.88      2084\n",
      "weighted avg       0.98      0.98      0.98      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1994    6]\n",
      " [  28   56]]\n",
      "\n",
      "CatBoost Performance with gaussian_noise:\n",
      "\n",
      "📊 CatBoostClassifier - Train Metrics\n",
      "Accuracy: 0.9971\n",
      "F1 Score: 0.9628\n",
      "Percent Errors Identified: 93.11%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8000\n",
      "           1       1.00      0.93      0.96       334\n",
      "\n",
      "    accuracy                           1.00      8334\n",
      "   macro avg       1.00      0.97      0.98      8334\n",
      "weighted avg       1.00      1.00      1.00      8334\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7999    1]\n",
      " [  23  311]]\n",
      "\n",
      "📊 CatBoostClassifier - Test Metrics\n",
      "Accuracy: 0.9856\n",
      "F1 Score: 0.8000\n",
      "Percent Errors Identified: 71.43%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2000\n",
      "           1       0.91      0.71      0.80        84\n",
      "\n",
      "    accuracy                           0.99      2084\n",
      "   macro avg       0.95      0.86      0.90      2084\n",
      "weighted avg       0.98      0.99      0.98      2084\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1994    6]\n",
      " [  24   60]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Different data augmentation techniques for tabular data\n",
    "def apply_data_augmentation(X_train, y_train, method=\"smote\"):\n",
    "    if method == \"smote\":\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "    elif method == \"adasyn\":\n",
    "        adasyn = ADASYN(random_state=42)\n",
    "        X_res, y_res = adasyn.fit_resample(X_train, y_train)\n",
    "    elif method == \"random_undersampling\":\n",
    "        X_res, y_res = resample(X_train, y_train, replace=False, n_samples=len(y_train[y_train == 1]), random_state=42)\n",
    "    elif method == \"random_oversampling\":\n",
    "        X_res, y_res = resample(X_train, y_train, replace=True, n_samples=len(y_train[y_train == 0]), random_state=42)\n",
    "    elif method == \"gaussian_noise\":\n",
    "        noise = np.random.normal(0, 0.1, X_train.shape)\n",
    "        X_res = X_train + noise\n",
    "        y_res = y_train  # No need to alter the labels\n",
    "    elif method == \"feature_permutation\":\n",
    "        permuted_X = X_train.copy()\n",
    "        for col in range(X_train.shape[1]):\n",
    "            permuted_X[:, col] = np.random.permutation(permuted_X[:, col])\n",
    "        X_res = permuted_X\n",
    "        y_res = y_train\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown augmentation method: {method}\")\n",
    "    \n",
    "    return X_res, y_res\n",
    "\n",
    "# Wrapper function for experimenting with different augmentation methods\n",
    "def experiment_with_augmentation(X_train, y_train, X_test, y_test, augmentation_methods):\n",
    "    for method in augmentation_methods:\n",
    "        print(f\"\\nTrying augmentation method: {method}\")\n",
    "        X_train_res, y_train_res = apply_data_augmentation(X_train, y_train, method)\n",
    "\n",
    "        # Standardize the augmented data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_res_scaled = scaler.fit_transform(X_train_res)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Train and evaluate models with augmented data\n",
    "        for name, model in models_dict.items():\n",
    "            print(f\"\\n{name} Performance with {method}:\")\n",
    "            evaluate_model(model, X_train_res_scaled, y_train_res, X_test_scaled, y_test)\n",
    "\n",
    "augmentation_methods = [\"smote\", \"adasyn\", \"random_undersampling\", \"random_oversampling\", \"gaussian_noise\"]\n",
    "\n",
    "# Run the experiment with all augmentation methods\n",
    "experiment_with_augmentation(X_train, y_train, X_test, y_test, augmentation_methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
